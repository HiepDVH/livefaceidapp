{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1b0262-3d52-418c-9072-59e0b821a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import model\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def lowlight(data_lowlight):\n",
    "    start = time.time()\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    scale_factor = 12\n",
    "\n",
    "    data_lowlight = data_lowlight.convert('RGB')\n",
    "\n",
    "    data_lowlight = np.asarray(data_lowlight) / 255.0\n",
    "\n",
    "    data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "\n",
    "    h = (data_lowlight.shape[0] // scale_factor) * scale_factor\n",
    "    w = (data_lowlight.shape[1] // scale_factor) * scale_factor\n",
    "    data_lowlight = data_lowlight[0:h, 0:w, :]\n",
    "    data_lowlight = data_lowlight.permute(2, 0, 1)\n",
    "    data_lowlight = data_lowlight.cuda().unsqueeze(0)\n",
    "\n",
    "    DCE_net = model.enhance_net_nopool(scale_factor).cuda()\n",
    "    DCE_net.load_state_dict(torch.load('snapshots_Zero_DCE++/Epoch99.pth'))\n",
    "    start = time.time()\n",
    "    enhanced_image, params_maps = DCE_net(data_lowlight)\n",
    "\n",
    "    end = time.time()\n",
    "    infer_time = end - start\n",
    "    print(f'infer_time: {infer_time}')\n",
    "    return enhanced_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bbbc09-d373-4266-b961-8475d61db24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer_time: 0.0005617141723632812\n",
      "infer_time: 0.0004975795745849609\n",
      "infer_time: 0.00049591064453125\n",
      "infer_time: 0.0005018711090087891\n",
      "infer_time: 0.0004944801330566406\n",
      "infer_time: 0.0005142688751220703\n",
      "infer_time: 0.0005056858062744141\n",
      "infer_time: 0.0004894733428955078\n",
      "infer_time: 0.0008141994476318359\n",
      "infer_time: 0.0005934238433837891\n",
      "infer_time: 0.0005054473876953125\n",
      "infer_time: 0.0005085468292236328\n",
      "infer_time: 0.0004856586456298828\n",
      "infer_time: 0.0005266666412353516\n",
      "infer_time: 0.0005385875701904297\n"
     ]
    }
   ],
   "source": [
    "test_low_light_images = os.listdir(\n",
    "    '/home/hiepdvh/low-light-recognition-trial/Zero-DCE++/lol_dataset/eval15/low'\n",
    ")\n",
    "\n",
    "for low_light_image in test_low_light_images:\n",
    "    low_light_image_path = os.path.join(\n",
    "        '/home/hiepdvh/low-light-recognition-trial/Zero-DCE++/lol_dataset/eval15/low',\n",
    "        low_light_image,\n",
    "    )\n",
    "    original_image = Image.open(low_light_image_path)\n",
    "    enhanced_image = lowlight(original_image)\n",
    "    result_path = os.path.join(\n",
    "        '/home/hiepdvh/low-light-recognition-trial/Zero-DCE++/lol_dataset/eval15/high',\n",
    "        low_light_image,\n",
    "    )\n",
    "    torchvision.utils.save_image(enhanced_image, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f250b1-90f9-4830-9eb7-3bfbd0f209df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from lpips import LPIPS\n",
    "from scipy.stats import entropy\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "def calculate_metrics(original_img, enhanced_img):\n",
    "    # Chuyển đổi ảnh từ [0, 255] sang [0, 1]\n",
    "    original_img = original_img.astype(np.float32) / 255.0\n",
    "    enhanced_img = enhanced_img.astype(np.float32) / 255.0\n",
    "    original_img.resize(enhanced_img.shape)\n",
    "    # PSNR\n",
    "    psnr_value = psnr(original_img, enhanced_img, data_range=1.0)\n",
    "\n",
    "    # SSIM\n",
    "    ssim_value, _ = ssim(original_img, enhanced_img, full=True, data_range=1.0)\n",
    "\n",
    "    # Entropy\n",
    "    entropy_original = entropy(original_img.flatten())\n",
    "    entropy_enhanced = entropy(enhanced_img.flatten())\n",
    "\n",
    "    # Standard Deviation\n",
    "    std_dev_original = np.std(original_img)\n",
    "    std_dev_enhanced = np.std(enhanced_img)\n",
    "    original_tensor = torch.from_numpy(original_img)\n",
    "    enhanced_tensor = torch.from_numpy(enhanced_img)\n",
    "    lpips_value = lpips_model(original_tensor, enhanced_tensor).item()\n",
    "    return (\n",
    "        psnr_value,\n",
    "        ssim_value,\n",
    "        entropy_original,\n",
    "        entropy_enhanced,\n",
    "        std_dev_original,\n",
    "        std_dev_enhanced,\n",
    "        lpips_value,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f166b0-c0a3-431a-903c-407fecea431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hiepdvh/miniconda3/envs/livefaceidapp/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hiepdvh/miniconda3/envs/livefaceidapp/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/hiepdvh/miniconda3/envs/livefaceidapp/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "665.png\n",
      "psnr: 13.839268922802699, ssim: 0.18199984216234696, entropy: 12.1690034866333, std: 0.019163131713867188, lpips: 0.41301247477531433\n",
      "22.png\n",
      "psnr: 11.099410584086474, ssim: 0.30083373389214335, entropy: 12.101876258850098, std: 0.0507991686463356, lpips: 0.31196820735931396\n",
      "778.png\n",
      "psnr: 14.5348520015447, ssim: 0.16601431221509239, entropy: 11.859112739562988, std: 0.02995860017836094, lpips: 0.3974076509475708\n",
      "780.png\n",
      "psnr: 13.753789428944948, ssim: 0.20230139691189927, entropy: 11.887100219726562, std: 0.05470995232462883, lpips: 0.4016571044921875\n",
      "111.png\n",
      "psnr: 10.742132299604938, ssim: 0.2986297827913984, entropy: 12.224459648132324, std: 0.042161352932453156, lpips: 0.290187269449234\n",
      "146.png\n",
      "psnr: 10.371230804369118, ssim: 0.3546604842240138, entropy: 12.196784973144531, std: 0.04989078640937805, lpips: 0.2696795165538788\n",
      "493.png\n",
      "psnr: 15.24459806501999, ssim: 0.18822141707498546, entropy: 11.851127624511719, std: 0.024508552625775337, lpips: 0.459808886051178\n",
      "547.png\n",
      "psnr: 11.382002039658783, ssim: 0.25419382440307564, entropy: 12.239801406860352, std: 0.030718756839632988, lpips: 0.32879793643951416\n",
      "23.png\n",
      "psnr: 13.348197885735537, ssim: 0.2111187785343877, entropy: 11.98460865020752, std: 0.029190421104431152, lpips: 0.4073067605495453\n",
      "1.png\n",
      "psnr: 11.494415933180218, ssim: 0.3218580056345849, entropy: 11.959158897399902, std: 0.09136145561933517, lpips: 0.27212151885032654\n",
      "55.png\n",
      "psnr: 13.033117715355239, ssim: 0.2206296922997491, entropy: 11.952927589416504, std: 0.03169437497854233, lpips: 0.38863590359687805\n",
      "669.png\n",
      "psnr: 11.093855823015366, ssim: 0.27677418846347557, entropy: 12.244046211242676, std: 0.03364130109548569, lpips: 0.33314865827560425\n",
      "748.png\n",
      "psnr: 12.208423552151753, ssim: 0.21808954401852787, entropy: 12.207273483276367, std: 0.035552728921175, lpips: 0.32003140449523926\n",
      "79.png\n",
      "psnr: 10.319025431922865, ssim: 0.32814536364952696, entropy: 12.27061939239502, std: 0.04021259397268295, lpips: 0.2731541693210602\n",
      "179.png\n",
      "psnr: 11.055988050707214, ssim: 0.3058729065067221, entropy: 12.309698104858398, std: 0.0289448294788599, lpips: 0.2810658812522888\n",
      "\n",
      " average_psnr: 12.23468723587332 \n",
      " average_ssim: 0.2552895515187953 \n",
      " average_entropy: 12.097173245747884 \n",
      " average_std: 0.03950053378939629 \n",
      " average_lpips: 0.3431988894939423\n"
     ]
    }
   ],
   "source": [
    "lpips_model = LPIPS(net='vgg')\n",
    "original_image_folder = (\n",
    "    '/home/hiepdvh/low-light-recognition-trial/Zero-DCE++/lol_dataset/eval15/high'\n",
    ")\n",
    "enhanced_image_folder = (\n",
    "    '/home/hiepdvh/low-light-recognition-trial/Zero-DCE++/lol_dataset/eval15/low'\n",
    ")\n",
    "\n",
    "images = os.listdir(original_image_folder)\n",
    "results = ''\n",
    "average_psnr = 0\n",
    "average_ssim = 0\n",
    "average_entropy = 0\n",
    "average_std = 0\n",
    "average_lpips = 0\n",
    "for i, image in enumerate(images):\n",
    "    original_image_path = os.path.join(original_image_folder, image)\n",
    "    enhanced_image_path = os.path.join(enhanced_image_folder, image)\n",
    "    original_img = cv2.imread(original_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    enhanced_img = cv2.imread(enhanced_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    (\n",
    "        psnr_value,\n",
    "        ssim_value,\n",
    "        entropy_original,\n",
    "        entropy_enhanced,\n",
    "        std_dev_original,\n",
    "        std_dev_enhanced,\n",
    "        lpips_value,\n",
    "    ) = calculate_metrics(original_img, enhanced_img)\n",
    "    result = f'{image}\\npsnr: {psnr_value}, ssim: {ssim_value}, entropy: {entropy_enhanced}, std: {std_dev_enhanced}, lpips: {lpips_value}'\n",
    "    results = results + result + '\\n'\n",
    "    average_psnr = (average_psnr*i + psnr_value)/(i+1)\n",
    "    average_ssim = (average_ssim*i + ssim_value)/(i+1)\n",
    "    average_entropy = (average_entropy*i + entropy_enhanced)/(i+1)\n",
    "    average_std= (average_std*i + std_dev_enhanced)/(i+1)\n",
    "    average_lpips = (average_lpips*i + lpips_value)/(i+1)\n",
    "\n",
    "print(results)\n",
    "print(f' average_psnr: {average_psnr} \\n average_ssim: {average_ssim} \\n average_entropy: {average_entropy} \\n average_std: {average_std} \\n average_lpips: {average_lpips}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac05a87-6fde-43d9-a007-c73a73dd2139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
