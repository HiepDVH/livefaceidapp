Total training examples: 2988
Loss at iteration 10 : 0.7882192134857178
Loss at iteration 20 : 0.5096421241760254
Loss at iteration 30 : 0.4581229090690613
Loss at iteration 40 : 0.41220274567604065
Loss at iteration 50 : 0.46117115020751953
Loss at iteration 60 : 0.4110095500946045
Loss at iteration 70 : 0.4449666738510132
Loss at iteration 80 : 0.39761775732040405
Loss at iteration 90 : 0.3833969831466675
Loss at iteration 100 : 0.4120365381240845
Loss at iteration 110 : 0.4091113209724426
Loss at iteration 120 : 0.36109405755996704
Loss at iteration 130 : 0.4363356828689575
Loss at iteration 140 : 0.4346325993537903
Loss at iteration 150 : 0.3097440004348755
Loss at iteration 160 : 0.3820694386959076
Loss at iteration 170 : 0.38386595249176025
Loss at iteration 180 : 0.4110015630722046
lowlight_train.py:68: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(DCE_net.parameters(), config.grad_clip_norm)
Loss at iteration 10 : 0.3772731125354767
Loss at iteration 20 : 0.3973071277141571
Loss at iteration 30 : 0.3598741292953491
Loss at iteration 40 : 0.3583127558231354
Loss at iteration 50 : 0.3545653820037842
Loss at iteration 60 : 0.37804853916168213
Loss at iteration 70 : 0.426908940076828
Loss at iteration 80 : 0.38211533427238464
Loss at iteration 90 : 0.4138428568840027
Loss at iteration 100 : 0.44766226410865784
Loss at iteration 110 : 0.45331501960754395
Loss at iteration 120 : 0.35364025831222534
Loss at iteration 130 : 0.4170076847076416
Loss at iteration 140 : 0.37045925855636597
Loss at iteration 150 : 0.42485979199409485
Loss at iteration 160 : 0.3554418087005615
Loss at iteration 170 : 0.4428482949733734
Loss at iteration 180 : 0.39791542291641235
Loss at iteration 10 : 0.4556483030319214
Loss at iteration 20 : 0.48984384536743164
Loss at iteration 30 : 0.3952024281024933
Loss at iteration 40 : 0.3836019039154053
Loss at iteration 50 : 0.36212849617004395
Loss at iteration 60 : 0.3793371319770813
Loss at iteration 70 : 0.33487704396247864
Loss at iteration 80 : 0.40330806374549866
Loss at iteration 90 : 0.41058218479156494
Loss at iteration 100 : 0.35150402784347534
Loss at iteration 110 : 0.38010916113853455
Loss at iteration 120 : 0.41150665283203125
Loss at iteration 130 : 0.36386212706565857
Loss at iteration 140 : 0.4050992429256439
Loss at iteration 150 : 0.4311935007572174
Loss at iteration 160 : 0.40195074677467346
Loss at iteration 170 : 0.4469819962978363
Loss at iteration 180 : 0.4854791462421417
Loss at iteration 10 : 0.37133848667144775
Loss at iteration 20 : 0.3430859446525574
Loss at iteration 30 : 0.38223230838775635
Loss at iteration 40 : 0.37522441148757935
Loss at iteration 50 : 0.36178427934646606
Loss at iteration 60 : 0.44846177101135254
Loss at iteration 70 : 0.4782281517982483
Loss at iteration 80 : 0.433132529258728
Loss at iteration 90 : 0.39018571376800537
Loss at iteration 100 : 0.44185495376586914
Loss at iteration 110 : 0.3632642328739166
Loss at iteration 120 : 0.4123676121234894
Loss at iteration 130 : 0.37206849455833435
Loss at iteration 140 : 0.5060758590698242
Loss at iteration 150 : 0.3385409116744995
Loss at iteration 160 : 0.41978955268859863
Loss at iteration 170 : 0.3528449833393097
Loss at iteration 180 : 0.3560182452201843
Loss at iteration 10 : 0.33916449546813965
Loss at iteration 20 : 0.35527554154396057
Loss at iteration 30 : 0.41272225975990295
Loss at iteration 40 : 0.37634915113449097
Loss at iteration 50 : 0.4002353549003601
Loss at iteration 60 : 0.41198909282684326
Loss at iteration 70 : 0.42900145053863525
Loss at iteration 80 : 0.37941962480545044
Loss at iteration 90 : 0.4567018151283264
Loss at iteration 100 : 0.4206482768058777
Loss at iteration 110 : 0.4422358274459839
Loss at iteration 120 : 0.4401908218860626
Loss at iteration 130 : 0.34624341130256653
Loss at iteration 140 : 0.3340785503387451
Loss at iteration 150 : 0.4137756824493408
Loss at iteration 160 : 0.3752109408378601
Loss at iteration 170 : 0.3973546624183655
Loss at iteration 180 : 0.43980008363723755
Loss at iteration 10 : 0.3934909403324127
Loss at iteration 20 : 0.35706406831741333
Loss at iteration 30 : 0.31668174266815186
Loss at iteration 40 : 0.34575170278549194
Loss at iteration 50 : 0.33490729331970215
Loss at iteration 60 : 0.4135940372943878
Loss at iteration 70 : 0.37165454030036926
Loss at iteration 80 : 0.446713387966156
Loss at iteration 90 : 0.3625197410583496
Loss at iteration 100 : 0.4048318862915039
Loss at iteration 110 : 0.45195063948631287
Loss at iteration 120 : 0.41920018196105957
Loss at iteration 130 : 0.4386492073535919
Loss at iteration 140 : 0.3247129023075104
Loss at iteration 150 : 0.43418413400650024
Loss at iteration 160 : 0.3705492615699768
Loss at iteration 170 : 0.3827296495437622
Loss at iteration 180 : 0.367941677570343
Total training examples: 2988
Loss at iteration 10 : 0.7998058199882507
Loss at iteration 20 : 0.5117201805114746
Loss at iteration 30 : 0.52716463804245
Loss at iteration 40 : 0.44096094369888306
Loss at iteration 50 : 0.5028882026672363
Loss at iteration 60 : 0.5194013118743896
Loss at iteration 70 : 0.44910579919815063
Loss at iteration 80 : 0.5090036988258362
Loss at iteration 90 : 0.3712102770805359
Loss at iteration 100 : 0.42910248041152954
Loss at iteration 110 : 0.4178521931171417
Loss at iteration 120 : 0.42440420389175415
Loss at iteration 130 : 0.3857344090938568
Loss at iteration 140 : 0.537136971950531
Loss at iteration 150 : 0.4197238087654114
Loss at iteration 160 : 0.347825288772583
Loss at iteration 170 : 0.34766146540641785
Loss at iteration 180 : 0.3963909447193146
lowlight_train.py:68: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(DCE_net.parameters(), config.grad_clip_norm)
Loss at iteration 10 : 0.4271489381790161
Loss at iteration 20 : 0.45183655619621277
Loss at iteration 30 : 0.3888281583786011
Loss at iteration 40 : 0.40211188793182373
Loss at iteration 50 : 0.40445125102996826
Loss at iteration 60 : 0.3310237526893616
Loss at iteration 70 : 0.4756339192390442
Loss at iteration 80 : 0.44005873799324036
Loss at iteration 90 : 0.43087029457092285
Loss at iteration 100 : 0.42816323041915894
Loss at iteration 110 : 0.3709261417388916
Loss at iteration 120 : 0.4317169189453125
Loss at iteration 130 : 0.4076700508594513
Loss at iteration 140 : 0.3537164330482483
Loss at iteration 150 : 0.3297816812992096
Loss at iteration 160 : 0.37237289547920227
Loss at iteration 170 : 0.35175853967666626
Loss at iteration 180 : 0.3654834032058716
Loss at iteration 10 : 0.4237098693847656
Loss at iteration 20 : 0.42108091711997986
Loss at iteration 30 : 0.3441857695579529
Loss at iteration 40 : 0.4405171871185303
Loss at iteration 50 : 0.3395332396030426
Loss at iteration 60 : 0.36162349581718445
Loss at iteration 70 : 0.4024656414985657
Loss at iteration 80 : 0.423977255821228
Loss at iteration 90 : 0.3853464126586914
Loss at iteration 100 : 0.35378748178482056
Loss at iteration 110 : 0.36128273606300354
Loss at iteration 120 : 0.3795439600944519
Loss at iteration 130 : 0.3766050934791565
Loss at iteration 140 : 0.3437296748161316
Loss at iteration 150 : 0.3826446235179901
Loss at iteration 160 : 0.4161511957645416
Loss at iteration 170 : 0.4199197590351105
Loss at iteration 180 : 0.38556528091430664
Loss at iteration 10 : 0.415405809879303
Loss at iteration 20 : 0.33429113030433655
Loss at iteration 30 : 0.3977864682674408
Loss at iteration 40 : 0.41382288932800293
Loss at iteration 50 : 0.3708088994026184
Loss at iteration 60 : 0.4032008945941925
Loss at iteration 70 : 0.4893750250339508
Loss at iteration 80 : 0.32621878385543823
Loss at iteration 90 : 0.4396243393421173
Loss at iteration 100 : 0.43480515480041504
Loss at iteration 110 : 0.4177750051021576
Loss at iteration 120 : 0.3317035734653473
Loss at iteration 130 : 0.44225019216537476
Loss at iteration 140 : 0.39335253834724426
Loss at iteration 150 : 0.36647331714630127
Loss at iteration 160 : 0.3401736319065094
Loss at iteration 170 : 0.3932783901691437
Loss at iteration 180 : 0.3580230474472046
Loss at iteration 10 : 0.3624243438243866
Loss at iteration 20 : 0.4644041657447815
Loss at iteration 30 : 0.43711787462234497
Loss at iteration 40 : 0.3842526972293854
Loss at iteration 50 : 0.33889222145080566
Loss at iteration 60 : 0.3709907531738281
Loss at iteration 70 : 0.37517261505126953
Loss at iteration 80 : 0.42596304416656494
Loss at iteration 90 : 0.4347001910209656
Loss at iteration 100 : 0.4323763847351074
Loss at iteration 110 : 0.42478540539741516
Loss at iteration 120 : 0.43089187145233154
Loss at iteration 130 : 0.4414770007133484
Loss at iteration 140 : 0.4019984304904938
Loss at iteration 150 : 0.4062018394470215
Loss at iteration 160 : 0.35959935188293457
Loss at iteration 170 : 0.35848087072372437
Loss at iteration 180 : 0.43548107147216797
Loss at iteration 10 : 0.3974717855453491
Loss at iteration 20 : 0.3494853973388672
Loss at iteration 30 : 0.44250476360321045
Loss at iteration 40 : 0.42934751510620117
Loss at iteration 50 : 0.4055071473121643
Loss at iteration 60 : 0.37162238359451294
Loss at iteration 70 : 0.30607733130455017
Loss at iteration 80 : 0.4733496308326721
Loss at iteration 90 : 0.38155826926231384
Loss at iteration 100 : 0.42075514793395996
Loss at iteration 110 : 0.44812989234924316
Loss at iteration 120 : 0.4119345545768738
Loss at iteration 130 : 0.46083515882492065
Loss at iteration 140 : 0.4467318058013916
Loss at iteration 150 : 0.4205940365791321
Loss at iteration 160 : 0.4161525368690491
Loss at iteration 170 : 0.36302241683006287
Loss at iteration 180 : 0.41150781512260437
Loss at iteration 10 : 0.38519909977912903
Loss at iteration 20 : 0.4358293116092682
Loss at iteration 30 : 0.4021643400192261
Loss at iteration 40 : 0.39137154817581177
Loss at iteration 50 : 0.40033429861068726
Loss at iteration 60 : 0.39468562602996826
Loss at iteration 70 : 0.3427029550075531
Loss at iteration 80 : 0.3682495951652527
Loss at iteration 90 : 0.3714936077594757
Loss at iteration 100 : 0.41911014914512634
Loss at iteration 110 : 0.43718022108078003
Loss at iteration 120 : 0.3663158416748047
Loss at iteration 130 : 0.3702271282672882
Loss at iteration 140 : 0.34895575046539307
Loss at iteration 150 : 0.36244824528694153
Loss at iteration 160 : 0.38539594411849976
Loss at iteration 170 : 0.4154514968395233
Loss at iteration 180 : 0.4139692187309265
Loss at iteration 10 : 0.3459654152393341
Loss at iteration 20 : 0.3747043013572693
Loss at iteration 30 : 0.330773264169693
Loss at iteration 40 : 0.4599318504333496
Loss at iteration 50 : 0.4695020318031311
Loss at iteration 60 : 0.4319366216659546
Loss at iteration 70 : 0.4845108985900879
Loss at iteration 80 : 0.3755408525466919
Loss at iteration 90 : 0.4200980067253113
Loss at iteration 100 : 0.3374772369861603
Loss at iteration 110 : 0.33459997177124023
Loss at iteration 120 : 0.41890954971313477
Loss at iteration 130 : 0.37916260957717896
Loss at iteration 140 : 0.38615041971206665
Loss at iteration 150 : 0.3496245741844177
Loss at iteration 160 : 0.4158065915107727
Loss at iteration 170 : 0.43789586424827576
Loss at iteration 180 : 0.3695116639137268
Loss at iteration 10 : 0.4825902283191681
Loss at iteration 20 : 0.2893112897872925
Loss at iteration 30 : 0.3823157846927643
Loss at iteration 40 : 0.3481743633747101
Loss at iteration 50 : 0.38801446557044983
Loss at iteration 60 : 0.46646058559417725
Loss at iteration 70 : 0.3565899133682251
Loss at iteration 80 : 0.40644797682762146
Loss at iteration 90 : 0.38818949460983276
Loss at iteration 100 : 0.3681984841823578
Loss at iteration 110 : 0.3721276521682739
Loss at iteration 120 : 0.40891093015670776
Loss at iteration 130 : 0.42105579376220703
Loss at iteration 140 : 0.4056840240955353
Loss at iteration 150 : 0.3414209187030792
Loss at iteration 160 : 0.388400673866272
Loss at iteration 170 : 0.3779814839363098
Loss at iteration 180 : 0.34452563524246216
Loss at iteration 10 : 0.4138141870498657
Loss at iteration 20 : 0.3865222632884979
Loss at iteration 30 : 0.3929586410522461
Loss at iteration 40 : 0.33662915229797363
Loss at iteration 50 : 0.36938247084617615
Loss at iteration 60 : 0.365871787071228
Loss at iteration 70 : 0.3895159959793091
Loss at iteration 80 : 0.39105021953582764
Loss at iteration 90 : 0.3658089339733124
Loss at iteration 100 : 0.3309202194213867
Loss at iteration 110 : 0.3975192606449127
Loss at iteration 120 : 0.4215773046016693
Loss at iteration 130 : 0.4664088487625122
Loss at iteration 140 : 0.35054120421409607
Loss at iteration 150 : 0.3606971800327301
Loss at iteration 160 : 0.4254363179206848
Loss at iteration 170 : 0.42017561197280884
Loss at iteration 180 : 0.38428008556365967
Loss at iteration 10 : 0.34833604097366333
Loss at iteration 20 : 0.3991188406944275
Loss at iteration 30 : 0.4891993999481201
Loss at iteration 40 : 0.3935275673866272
Loss at iteration 50 : 0.32279765605926514
Loss at iteration 60 : 0.3376966714859009
Loss at iteration 70 : 0.37598973512649536
Loss at iteration 80 : 0.43107831478118896
Loss at iteration 90 : 0.3777247369289398
Loss at iteration 100 : 0.32399922609329224
Loss at iteration 110 : 0.42352765798568726
Loss at iteration 120 : 0.36107075214385986
Loss at iteration 130 : 0.4093429446220398
Loss at iteration 140 : 0.38871094584465027
Loss at iteration 150 : 0.31912916898727417
Loss at iteration 160 : 0.3573518991470337
Loss at iteration 170 : 0.36826664209365845
Loss at iteration 180 : 0.45533913373947144
Loss at iteration 10 : 0.3781532645225525
Loss at iteration 20 : 0.3714436888694763
Loss at iteration 30 : 0.3318227529525757
Loss at iteration 40 : 0.3492357134819031
Loss at iteration 50 : 0.3451788127422333
Loss at iteration 60 : 0.35250693559646606
Loss at iteration 70 : 0.4044983386993408
Loss at iteration 80 : 0.35841572284698486
Loss at iteration 90 : 0.3887958824634552
Loss at iteration 100 : 0.43323177099227905
Loss at iteration 110 : 0.46652454137802124
Loss at iteration 120 : 0.3977110981941223
Loss at iteration 130 : 0.44874995946884155
Loss at iteration 140 : 0.4857359528541565
Loss at iteration 150 : 0.3289910852909088
Loss at iteration 160 : 0.38086533546447754
Loss at iteration 170 : 0.3028276264667511
Loss at iteration 180 : 0.3720676898956299
Loss at iteration 10 : 0.35990649461746216
Loss at iteration 20 : 0.3896309733390808
Loss at iteration 30 : 0.36890554428100586
Loss at iteration 40 : 0.3570457398891449
Loss at iteration 50 : 0.4006000757217407
Loss at iteration 60 : 0.42154693603515625
Loss at iteration 70 : 0.4292043447494507
Loss at iteration 80 : 0.495547890663147
Loss at iteration 90 : 0.3847559690475464
Loss at iteration 100 : 0.4498952627182007
Loss at iteration 110 : 0.38601142168045044
Loss at iteration 120 : 0.39935290813446045
Loss at iteration 130 : 0.48254650831222534
Loss at iteration 140 : 0.4378981590270996
Loss at iteration 150 : 0.3765415549278259
Loss at iteration 160 : 0.3724045753479004
Loss at iteration 170 : 0.38767528533935547
Loss at iteration 180 : 0.49700087308883667
Loss at iteration 10 : 0.32573243975639343
Loss at iteration 20 : 0.34873417019844055
Loss at iteration 30 : 0.3851339817047119
Loss at iteration 40 : 0.35515111684799194
Loss at iteration 50 : 0.3858516812324524
Loss at iteration 60 : 0.4046013355255127
Loss at iteration 70 : 0.4784509241580963
Loss at iteration 80 : 0.3946913480758667
Loss at iteration 90 : 0.40318194031715393
Loss at iteration 100 : 0.3111104369163513
Loss at iteration 110 : 0.3526739478111267
Loss at iteration 120 : 0.40370938181877136
Loss at iteration 130 : 0.3614429831504822
Loss at iteration 140 : 0.37347412109375
Loss at iteration 150 : 0.403492271900177
Loss at iteration 160 : 0.4076383709907532
Loss at iteration 170 : 0.3805941343307495
Loss at iteration 180 : 0.4261093735694885
Loss at iteration 10 : 0.441440224647522
Loss at iteration 20 : 0.4052996039390564
Loss at iteration 30 : 0.37075960636138916
Loss at iteration 40 : 0.35870662331581116
Loss at iteration 50 : 0.4562644958496094
Loss at iteration 60 : 0.30916622281074524
Loss at iteration 70 : 0.41761770844459534
Loss at iteration 80 : 0.4177476167678833
Loss at iteration 90 : 0.3188645839691162
Loss at iteration 100 : 0.3279661238193512
Loss at iteration 110 : 0.3317683935165405
Loss at iteration 120 : 0.4039931297302246
Loss at iteration 130 : 0.41538241505622864
Loss at iteration 140 : 0.44500941038131714
Loss at iteration 150 : 0.33647578954696655
Loss at iteration 160 : 0.4351571202278137
Loss at iteration 170 : 0.3449053168296814
Loss at iteration 180 : 0.41813164949417114
Loss at iteration 10 : 0.38758599758148193
Loss at iteration 20 : 0.3368264436721802
Loss at iteration 30 : 0.36616432666778564
Loss at iteration 40 : 0.303566038608551
Loss at iteration 50 : 0.49260252714157104
Loss at iteration 60 : 0.30175724625587463
Loss at iteration 70 : 0.382936954498291
Loss at iteration 80 : 0.3752742409706116
Loss at iteration 90 : 0.31752240657806396
Loss at iteration 100 : 0.42864111065864563
Loss at iteration 110 : 0.36097097396850586
Loss at iteration 120 : 0.38246703147888184
Loss at iteration 130 : 0.4044630527496338
Loss at iteration 140 : 0.4112873673439026
Loss at iteration 150 : 0.33721059560775757
Loss at iteration 160 : 0.4235830307006836
Loss at iteration 170 : 0.42580562829971313
Loss at iteration 180 : 0.38047799468040466
Loss at iteration 10 : 0.367227703332901
Loss at iteration 20 : 0.4630357623100281
Loss at iteration 30 : 0.35829296708106995
Loss at iteration 40 : 0.3940843641757965
Loss at iteration 50 : 0.326170414686203
Loss at iteration 60 : 0.4140622615814209
Loss at iteration 70 : 0.3776600956916809
Loss at iteration 80 : 0.37665659189224243
Loss at iteration 90 : 0.4314643144607544
Loss at iteration 100 : 0.3399667739868164
Loss at iteration 110 : 0.31848639249801636
Loss at iteration 120 : 0.3414340019226074
Loss at iteration 130 : 0.4739798903465271
Loss at iteration 140 : 0.3835998475551605
Loss at iteration 150 : 0.31539681553840637
Loss at iteration 160 : 0.5297037363052368
Loss at iteration 170 : 0.3620064854621887
Loss at iteration 180 : 0.45663028955459595
Loss at iteration 10 : 0.39468634128570557
Loss at iteration 20 : 0.3670458495616913
Loss at iteration 30 : 0.33206528425216675
Loss at iteration 40 : 0.305461049079895
Loss at iteration 50 : 0.3319830000400543
Loss at iteration 60 : 0.3604247272014618
Loss at iteration 70 : 0.4261022210121155
Loss at iteration 80 : 0.43554937839508057
Loss at iteration 90 : 0.3609228730201721
Loss at iteration 100 : 0.48037081956863403
Loss at iteration 110 : 0.4202815890312195
Loss at iteration 120 : 0.4256857931613922
Loss at iteration 130 : 0.4395734965801239
Loss at iteration 140 : 0.3505648374557495
Loss at iteration 150 : 0.3751331567764282
Loss at iteration 160 : 0.4190317988395691
Loss at iteration 170 : 0.47524020075798035
Loss at iteration 180 : 0.4048115015029907
Loss at iteration 10 : 0.41659027338027954
Loss at iteration 20 : 0.35311639308929443
Loss at iteration 30 : 0.3027970790863037
Loss at iteration 40 : 0.3500269055366516
Loss at iteration 50 : 0.34583064913749695
Loss at iteration 60 : 0.3731921315193176
Loss at iteration 70 : 0.34094539284706116
Loss at iteration 80 : 0.42803114652633667
Loss at iteration 90 : 0.3321315050125122
Loss at iteration 100 : 0.3540407419204712
Loss at iteration 110 : 0.4159511923789978
Loss at iteration 120 : 0.3999062776565552
Loss at iteration 130 : 0.3897397518157959
Loss at iteration 140 : 0.3942488431930542
Loss at iteration 150 : 0.4781472980976105
Loss at iteration 160 : 0.35311776399612427
Loss at iteration 170 : 0.46973562240600586
Loss at iteration 180 : 0.3362097144126892
Loss at iteration 10 : 0.38273346424102783
Loss at iteration 20 : 0.352551132440567
Loss at iteration 30 : 0.37777191400527954
Loss at iteration 40 : 0.4146547317504883
Loss at iteration 50 : 0.4227604269981384
Loss at iteration 60 : 0.45525842905044556
Loss at iteration 70 : 0.5213742852210999
Loss at iteration 80 : 0.42936018109321594
Loss at iteration 90 : 0.47871729731559753
Loss at iteration 100 : 0.4554131031036377
Loss at iteration 110 : 0.4015319347381592
Loss at iteration 120 : 0.4332478642463684
Loss at iteration 130 : 0.3800966143608093
Loss at iteration 140 : 0.3764141798019409
Loss at iteration 150 : 0.35543641448020935
Loss at iteration 160 : 0.3631022572517395
Loss at iteration 170 : 0.40118926763534546
Loss at iteration 180 : 0.3762843608856201
Loss at iteration 10 : 0.41440349817276
Loss at iteration 20 : 0.33821481466293335
Loss at iteration 30 : 0.4329037070274353
Loss at iteration 40 : 0.3671518564224243
Loss at iteration 50 : 0.31444603204727173
Loss at iteration 60 : 0.3918185234069824
Loss at iteration 70 : 0.36033329367637634
Loss at iteration 80 : 0.36330345273017883
Loss at iteration 90 : 0.3588477373123169
Loss at iteration 100 : 0.43034571409225464
Loss at iteration 110 : 0.3994597792625427
Loss at iteration 120 : 0.4082399010658264
Loss at iteration 130 : 0.42915791273117065
Loss at iteration 140 : 0.3485547602176666
Loss at iteration 150 : 0.3597371578216553
Loss at iteration 160 : 0.37001290917396545
Loss at iteration 170 : 0.382399320602417
Loss at iteration 180 : 0.4523884057998657
Loss at iteration 10 : 0.42022085189819336
Loss at iteration 20 : 0.4214688837528229
Loss at iteration 30 : 0.364646852016449
Loss at iteration 40 : 0.4564569890499115
Loss at iteration 50 : 0.3495652377605438
Loss at iteration 60 : 0.45896202325820923
Loss at iteration 70 : 0.42919036746025085
Loss at iteration 80 : 0.299586683511734
Loss at iteration 90 : 0.3556472659111023
Loss at iteration 100 : 0.3335718512535095
Loss at iteration 110 : 0.4274580180644989
Loss at iteration 120 : 0.3915281295776367
Loss at iteration 130 : 0.3449385166168213
Loss at iteration 140 : 0.3645750880241394
Loss at iteration 150 : 0.3842063546180725
Loss at iteration 160 : 0.3969256579875946
Loss at iteration 170 : 0.44129398465156555
Loss at iteration 180 : 0.3718545436859131
Loss at iteration 10 : 0.4080744981765747
Loss at iteration 20 : 0.3876439034938812
Loss at iteration 30 : 0.3660404682159424
Loss at iteration 40 : 0.31835946440696716
Loss at iteration 50 : 0.35517042875289917
Loss at iteration 60 : 0.36185628175735474
Loss at iteration 70 : 0.3433658480644226
Loss at iteration 80 : 0.3811628520488739
Loss at iteration 90 : 0.34383195638656616
Loss at iteration 100 : 0.4160979390144348
Loss at iteration 110 : 0.38793623447418213
Loss at iteration 120 : 0.37779662013053894
Loss at iteration 130 : 0.37374216318130493
Loss at iteration 140 : 0.34697839617729187
Loss at iteration 150 : 0.3114655911922455
Loss at iteration 160 : 0.43460848927497864
Loss at iteration 170 : 0.41824817657470703
Loss at iteration 180 : 0.425200879573822
Loss at iteration 10 : 0.4741095304489136
Loss at iteration 20 : 0.40194112062454224
Loss at iteration 30 : 0.40789610147476196
Loss at iteration 40 : 0.41915637254714966
Loss at iteration 50 : 0.3784859776496887
Loss at iteration 60 : 0.3393835425376892
Loss at iteration 70 : 0.45021307468414307
Loss at iteration 80 : 0.2943834960460663
Loss at iteration 90 : 0.30594494938850403
Loss at iteration 100 : 0.4235435426235199
Loss at iteration 110 : 0.39209121465682983
Loss at iteration 120 : 0.36341342329978943
Loss at iteration 130 : 0.36238619685173035
Loss at iteration 140 : 0.40915143489837646
Loss at iteration 150 : 0.3950009346008301
Loss at iteration 160 : 0.299437940120697
Loss at iteration 170 : 0.3883460462093353
Loss at iteration 180 : 0.44872424006462097
Loss at iteration 10 : 0.3873961865901947
Loss at iteration 20 : 0.3981618583202362
Loss at iteration 30 : 0.39864200353622437
Loss at iteration 40 : 0.47660452127456665
Loss at iteration 50 : 0.4433841407299042
Loss at iteration 60 : 0.4012657701969147
Loss at iteration 70 : 0.40733280777931213
Loss at iteration 80 : 0.46033209562301636
Loss at iteration 90 : 0.3467620313167572
Loss at iteration 100 : 0.4206317067146301
Loss at iteration 110 : 0.3213624358177185
Loss at iteration 120 : 0.3959398865699768
Loss at iteration 130 : 0.3991706967353821
Loss at iteration 140 : 0.4457462430000305
Loss at iteration 150 : 0.40817511081695557
Loss at iteration 160 : 0.3691120445728302
Loss at iteration 170 : 0.399527907371521
Loss at iteration 180 : 0.36020219326019287
Loss at iteration 10 : 0.35228443145751953
Loss at iteration 20 : 0.4539502263069153
Loss at iteration 30 : 0.33560195565223694
Loss at iteration 40 : 0.37220755219459534
Loss at iteration 50 : 0.395385205745697
Loss at iteration 60 : 0.37549132108688354
Loss at iteration 70 : 0.3291400074958801
Loss at iteration 80 : 0.4355408549308777
Loss at iteration 90 : 0.34658342599868774
Loss at iteration 100 : 0.5267682671546936
Loss at iteration 110 : 0.3322860598564148
Loss at iteration 120 : 0.33226412534713745
Loss at iteration 130 : 0.38084590435028076
Loss at iteration 140 : 0.378592312335968
Loss at iteration 150 : 0.4031289219856262
Loss at iteration 160 : 0.4177805185317993
Loss at iteration 170 : 0.413867324590683
Loss at iteration 180 : 0.37828394770622253
Loss at iteration 10 : 0.3408333659172058
Loss at iteration 20 : 0.37623512744903564
Loss at iteration 30 : 0.3651646077632904
Loss at iteration 40 : 0.3431134819984436
Loss at iteration 50 : 0.3778131306171417
Loss at iteration 60 : 0.33713194727897644
Loss at iteration 70 : 0.4096384644508362
Loss at iteration 80 : 0.4108700752258301
Loss at iteration 90 : 0.3841216266155243
Loss at iteration 100 : 0.34594303369522095
Loss at iteration 110 : 0.34409084916114807
Loss at iteration 120 : 0.3607693910598755
Loss at iteration 130 : 0.4428214430809021
Loss at iteration 140 : 0.35291793942451477
Loss at iteration 150 : 0.40262025594711304
Loss at iteration 160 : 0.30181747674942017
Loss at iteration 170 : 0.32955819368362427
Loss at iteration 180 : 0.3827926218509674
Loss at iteration 10 : 0.46149787306785583
Loss at iteration 20 : 0.35602983832359314
Loss at iteration 30 : 0.41419410705566406
Loss at iteration 40 : 0.4067123830318451
Loss at iteration 50 : 0.38911816477775574
Loss at iteration 60 : 0.40422913432121277
Loss at iteration 70 : 0.404962420463562
Loss at iteration 80 : 0.35254597663879395
Loss at iteration 90 : 0.3915679454803467
Loss at iteration 100 : 0.38244083523750305
Loss at iteration 110 : 0.34874436259269714
Loss at iteration 120 : 0.43237486481666565
Loss at iteration 130 : 0.40937817096710205
Loss at iteration 140 : 0.44074201583862305
Loss at iteration 150 : 0.3716323971748352
Loss at iteration 160 : 0.36972910165786743
Loss at iteration 170 : 0.34443455934524536
Loss at iteration 180 : 0.41710519790649414
Loss at iteration 10 : 0.3795126974582672
Loss at iteration 20 : 0.37214627861976624
Loss at iteration 30 : 0.4789445400238037
Loss at iteration 40 : 0.41712328791618347
Loss at iteration 50 : 0.34340524673461914
Loss at iteration 60 : 0.36261558532714844
Loss at iteration 70 : 0.36567991971969604
Loss at iteration 80 : 0.4136558175086975
Loss at iteration 90 : 0.389781653881073
Loss at iteration 100 : 0.37056171894073486
Loss at iteration 110 : 0.33163923025131226
Loss at iteration 120 : 0.321188747882843
Loss at iteration 130 : 0.40241625905036926
Loss at iteration 140 : 0.41742458939552307
Loss at iteration 150 : 0.42029377818107605
Loss at iteration 160 : 0.4716889560222626
Loss at iteration 170 : 0.47515207529067993
Loss at iteration 180 : 0.47655659914016724
Loss at iteration 10 : 0.36694392561912537
Loss at iteration 20 : 0.40564239025115967
Loss at iteration 30 : 0.3495672941207886
Loss at iteration 40 : 0.3619571030139923
Loss at iteration 50 : 0.3634762763977051
Loss at iteration 60 : 0.35020679235458374
Loss at iteration 70 : 0.4653628170490265
Loss at iteration 80 : 0.3498031497001648
Loss at iteration 90 : 0.4058423638343811
Loss at iteration 100 : 0.41782742738723755
Loss at iteration 110 : 0.4102153480052948
Loss at iteration 120 : 0.3585558235645294
Loss at iteration 130 : 0.39134150743484497
Loss at iteration 140 : 0.3926665186882019
Loss at iteration 150 : 0.4027342200279236
Loss at iteration 160 : 0.375888466835022
Loss at iteration 170 : 0.3530893921852112
Loss at iteration 180 : 0.40686649084091187
Loss at iteration 10 : 0.3925338387489319
Loss at iteration 20 : 0.3405202329158783
Loss at iteration 30 : 0.4573834538459778
Loss at iteration 40 : 0.36162155866622925
Loss at iteration 50 : 0.3198563754558563
Loss at iteration 60 : 0.37462082505226135
Loss at iteration 70 : 0.3732464909553528
Loss at iteration 80 : 0.3230050802230835
Loss at iteration 90 : 0.41704845428466797
Loss at iteration 100 : 0.39015233516693115
Loss at iteration 110 : 0.38141560554504395
Loss at iteration 120 : 0.3433375060558319
Loss at iteration 130 : 0.3482033610343933
Loss at iteration 140 : 0.4357834458351135
Loss at iteration 150 : 0.48526275157928467
Loss at iteration 160 : 0.36593276262283325
Loss at iteration 170 : 0.34318652749061584
Loss at iteration 180 : 0.38590899109840393
Loss at iteration 10 : 0.34362971782684326
Loss at iteration 20 : 0.4723806381225586
Loss at iteration 30 : 0.48296844959259033
Loss at iteration 40 : 0.3513375520706177
Loss at iteration 50 : 0.39891481399536133
Loss at iteration 60 : 0.332783043384552
Loss at iteration 70 : 0.36642125248908997
Loss at iteration 80 : 0.42849719524383545
Loss at iteration 90 : 0.40505337715148926
Loss at iteration 100 : 0.3973129391670227
Loss at iteration 110 : 0.3857051134109497
Loss at iteration 120 : 0.31131911277770996
Loss at iteration 130 : 0.3935554623603821
Loss at iteration 140 : 0.3958098888397217
Loss at iteration 150 : 0.4113389551639557
Loss at iteration 160 : 0.3857018053531647
Loss at iteration 170 : 0.39620018005371094
Loss at iteration 180 : 0.3569346070289612
Loss at iteration 10 : 0.41803568601608276
Loss at iteration 20 : 0.33930012583732605
Loss at iteration 30 : 0.3855551779270172
Loss at iteration 40 : 0.3502025008201599
Loss at iteration 50 : 0.36016708612442017
Loss at iteration 60 : 0.38604241609573364
Loss at iteration 70 : 0.3715016543865204
Loss at iteration 80 : 0.3553052842617035
Loss at iteration 90 : 0.3750513195991516
Loss at iteration 100 : 0.3868778347969055
Loss at iteration 110 : 0.4205957055091858
Loss at iteration 120 : 0.39222270250320435
Loss at iteration 130 : 0.38182640075683594
Loss at iteration 140 : 0.42315804958343506
Loss at iteration 150 : 0.4168154001235962
Loss at iteration 160 : 0.45422637462615967
Loss at iteration 170 : 0.37208831310272217
Loss at iteration 180 : 0.39327025413513184
Loss at iteration 10 : 0.32120460271835327
Loss at iteration 20 : 0.34019502997398376
Loss at iteration 30 : 0.35450974106788635
Loss at iteration 40 : 0.3376682996749878
Loss at iteration 50 : 0.40899717807769775
Loss at iteration 60 : 0.3420149087905884
Loss at iteration 70 : 0.38648679852485657
Loss at iteration 80 : 0.38656604290008545
Loss at iteration 90 : 0.4002807140350342
Loss at iteration 100 : 0.3796047568321228
Loss at iteration 110 : 0.40278416872024536
Loss at iteration 120 : 0.3896336257457733
Loss at iteration 130 : 0.4233425259590149
Loss at iteration 140 : 0.36929458379745483
Loss at iteration 150 : 0.3909023404121399
Loss at iteration 160 : 0.3759971559047699
Loss at iteration 170 : 0.35697004199028015
Loss at iteration 180 : 0.36511197686195374
Loss at iteration 10 : 0.3971593379974365
Loss at iteration 20 : 0.3675359785556793
Loss at iteration 30 : 0.4284505844116211
Loss at iteration 40 : 0.38407835364341736
Loss at iteration 50 : 0.36657845973968506
Loss at iteration 60 : 0.37022584676742554
Loss at iteration 70 : 0.3745327293872833
Loss at iteration 80 : 0.3847208023071289
Loss at iteration 90 : 0.4285815954208374
Loss at iteration 100 : 0.409961998462677
Loss at iteration 110 : 0.35116738080978394
Loss at iteration 120 : 0.35790735483169556
Loss at iteration 130 : 0.3554195463657379
Loss at iteration 140 : 0.30128154158592224
Loss at iteration 150 : 0.4432554244995117
Loss at iteration 160 : 0.4546261429786682
Loss at iteration 170 : 0.33714839816093445
Loss at iteration 180 : 0.4187453091144562
Loss at iteration 10 : 0.41237959265708923
Loss at iteration 20 : 0.3727271854877472
Loss at iteration 30 : 0.3840128183364868
Loss at iteration 40 : 0.361196368932724
Loss at iteration 50 : 0.3568265438079834
Loss at iteration 60 : 0.36898136138916016
Loss at iteration 70 : 0.36846795678138733
Loss at iteration 80 : 0.38661885261535645
Loss at iteration 90 : 0.3229904770851135
Loss at iteration 100 : 0.3564201891422272
Loss at iteration 110 : 0.33611345291137695
Loss at iteration 120 : 0.44071805477142334
Loss at iteration 130 : 0.3819729685783386
Loss at iteration 140 : 0.37053561210632324
Loss at iteration 150 : 0.41333886981010437
Loss at iteration 160 : 0.36133062839508057
Loss at iteration 170 : 0.4161427915096283
Loss at iteration 180 : 0.39180195331573486
Loss at iteration 10 : 0.4168283939361572
Loss at iteration 20 : 0.384109765291214
Loss at iteration 30 : 0.39062079787254333
Loss at iteration 40 : 0.3510987460613251
Loss at iteration 50 : 0.4230215549468994
Loss at iteration 60 : 0.3865819573402405
Loss at iteration 70 : 0.34121331572532654
Loss at iteration 80 : 0.4413021206855774
Loss at iteration 90 : 0.4583030939102173
Loss at iteration 100 : 0.46338391304016113
Loss at iteration 110 : 0.33696886897087097
Loss at iteration 120 : 0.3810829520225525
Loss at iteration 130 : 0.41291502118110657
Loss at iteration 140 : 0.39327651262283325
Loss at iteration 150 : 0.3301727771759033
Loss at iteration 160 : 0.3882766366004944
Loss at iteration 170 : 0.41498008370399475
Loss at iteration 180 : 0.39860594272613525
Loss at iteration 10 : 0.41761288046836853
Loss at iteration 20 : 0.32637643814086914
Loss at iteration 30 : 0.34885409474372864
Loss at iteration 40 : 0.44197338819503784
Loss at iteration 50 : 0.395402729511261
Loss at iteration 60 : 0.33180418610572815
Loss at iteration 70 : 0.3598015010356903
Loss at iteration 80 : 0.3760068416595459
Loss at iteration 90 : 0.3450045883655548
Loss at iteration 100 : 0.3915695548057556
Loss at iteration 110 : 0.3289448916912079
Loss at iteration 120 : 0.3841400444507599
Loss at iteration 130 : 0.37515121698379517
Loss at iteration 140 : 0.4136050343513489
Loss at iteration 150 : 0.3679029941558838
Loss at iteration 160 : 0.3786805272102356
Loss at iteration 170 : 0.31905263662338257
Loss at iteration 180 : 0.3936319947242737
Loss at iteration 10 : 0.36055630445480347
Loss at iteration 20 : 0.3610009253025055
Loss at iteration 30 : 0.39348703622817993
Loss at iteration 40 : 0.4507872462272644
Loss at iteration 50 : 0.4209992289543152
Loss at iteration 60 : 0.4177466630935669
Loss at iteration 70 : 0.33496057987213135
Loss at iteration 80 : 0.4436732530593872
Loss at iteration 90 : 0.3014994263648987
Loss at iteration 100 : 0.39107728004455566
Loss at iteration 110 : 0.48877519369125366
Loss at iteration 120 : 0.36029279232025146
Loss at iteration 130 : 0.3322741687297821
Loss at iteration 140 : 0.3291908800601959
Loss at iteration 150 : 0.35706329345703125
Loss at iteration 160 : 0.4425073564052582
Loss at iteration 170 : 0.42659473419189453
Loss at iteration 180 : 0.4709153473377228
Loss at iteration 10 : 0.3558374047279358
Loss at iteration 20 : 0.4163697361946106
Loss at iteration 30 : 0.32754069566726685
Loss at iteration 40 : 0.42898494005203247
Loss at iteration 50 : 0.45089924335479736
Loss at iteration 60 : 0.3276459574699402
Loss at iteration 70 : 0.33491525053977966
Loss at iteration 80 : 0.3277263045310974
Loss at iteration 90 : 0.30694159865379333
Loss at iteration 100 : 0.35498231649398804
Loss at iteration 110 : 0.325805127620697
Loss at iteration 120 : 0.43333932757377625
Loss at iteration 130 : 0.392151415348053
Loss at iteration 140 : 0.35811376571655273
Loss at iteration 150 : 0.35656312108039856
Loss at iteration 160 : 0.45270949602127075
Loss at iteration 170 : 0.33868324756622314
Loss at iteration 180 : 0.360095351934433
Loss at iteration 10 : 0.38732418417930603
Loss at iteration 20 : 0.4049733579158783
Loss at iteration 30 : 0.41857612133026123
Loss at iteration 40 : 0.3598743975162506
Loss at iteration 50 : 0.48090577125549316
Loss at iteration 60 : 0.4254288673400879
Loss at iteration 70 : 0.4194714426994324
Loss at iteration 80 : 0.3806716799736023
Loss at iteration 90 : 0.2516162395477295
Loss at iteration 100 : 0.3410271406173706
Loss at iteration 110 : 0.3832475543022156
Loss at iteration 120 : 0.39600229263305664
Loss at iteration 130 : 0.4131646454334259
Loss at iteration 140 : 0.36691319942474365
Loss at iteration 150 : 0.36918890476226807
Loss at iteration 160 : 0.38356655836105347
Loss at iteration 170 : 0.4384157061576843
Loss at iteration 180 : 0.417646199464798
Loss at iteration 10 : 0.3535993695259094
Loss at iteration 20 : 0.40921491384506226
Loss at iteration 30 : 0.42954161763191223
Loss at iteration 40 : 0.4351658523082733
Loss at iteration 50 : 0.3566204905509949
Loss at iteration 60 : 0.405400812625885
Loss at iteration 70 : 0.3723452687263489
Loss at iteration 80 : 0.35343044996261597
Loss at iteration 90 : 0.3458440899848938
Loss at iteration 100 : 0.4051324129104614
Loss at iteration 110 : 0.4427260160446167
Loss at iteration 120 : 0.3679168224334717
Loss at iteration 130 : 0.3835127353668213
Loss at iteration 140 : 0.4544232487678528
Loss at iteration 150 : 0.4154440462589264
Loss at iteration 160 : 0.47450461983680725
Loss at iteration 170 : 0.3891521990299225
Loss at iteration 180 : 0.4292141795158386
Loss at iteration 10 : 0.3947141766548157
Loss at iteration 20 : 0.4277278780937195
Loss at iteration 30 : 0.3985688090324402
Loss at iteration 40 : 0.3282364010810852
Loss at iteration 50 : 0.42236340045928955
Loss at iteration 60 : 0.4144369661808014
Loss at iteration 70 : 0.33620935678482056
Loss at iteration 80 : 0.43090879917144775
Loss at iteration 90 : 0.34808826446533203
Loss at iteration 100 : 0.3510563373565674
Loss at iteration 110 : 0.37483638525009155
Loss at iteration 120 : 0.3913460671901703
Loss at iteration 130 : 0.3843024969100952
Loss at iteration 140 : 0.3716096878051758
Loss at iteration 150 : 0.41228187084198
Loss at iteration 160 : 0.4063688814640045
Loss at iteration 170 : 0.42409902811050415
Loss at iteration 180 : 0.38171276450157166
Loss at iteration 10 : 0.3452713191509247
Loss at iteration 20 : 0.37330231070518494
Loss at iteration 30 : 0.4137163758277893
Loss at iteration 40 : 0.43987375497817993
Loss at iteration 50 : 0.41850608587265015
Loss at iteration 60 : 0.43039244413375854
Loss at iteration 70 : 0.3809797465801239
Loss at iteration 80 : 0.31833648681640625
Loss at iteration 90 : 0.3575178384780884
Loss at iteration 100 : 0.3775351643562317
Loss at iteration 110 : 0.440436452627182
Loss at iteration 120 : 0.3581581115722656
Loss at iteration 130 : 0.4639034569263458
Loss at iteration 140 : 0.2926860749721527
Loss at iteration 150 : 0.42025429010391235
Loss at iteration 160 : 0.3316575884819031
Loss at iteration 170 : 0.35431069135665894
Loss at iteration 180 : 0.44832921028137207
Loss at iteration 10 : 0.34037768840789795
Loss at iteration 20 : 0.33050772547721863
Loss at iteration 30 : 0.39503321051597595
Loss at iteration 40 : 0.418013334274292
Loss at iteration 50 : 0.4235844314098358
Loss at iteration 60 : 0.3639789819717407
Loss at iteration 70 : 0.3588413596153259
Loss at iteration 80 : 0.3841046690940857
Loss at iteration 90 : 0.39420285820961
Loss at iteration 100 : 0.4662431478500366
Loss at iteration 110 : 0.4033517837524414
Loss at iteration 120 : 0.42963433265686035
Loss at iteration 130 : 0.4315810203552246
Loss at iteration 140 : 0.3874046206474304
Loss at iteration 150 : 0.46315744519233704
Loss at iteration 160 : 0.446882426738739
Loss at iteration 170 : 0.34908798336982727
Loss at iteration 180 : 0.3511616289615631
Loss at iteration 10 : 0.35002797842025757
Loss at iteration 20 : 0.3780220150947571
Loss at iteration 30 : 0.3566771149635315
Loss at iteration 40 : 0.41568443179130554
Loss at iteration 50 : 0.3829784095287323
Loss at iteration 60 : 0.3956674635410309
Loss at iteration 70 : 0.37965089082717896
Loss at iteration 80 : 0.3680230379104614
Loss at iteration 90 : 0.4512728452682495
Loss at iteration 100 : 0.32880473136901855
Loss at iteration 110 : 0.3718847632408142
Loss at iteration 120 : 0.3704044222831726
Loss at iteration 130 : 0.35048139095306396
Loss at iteration 140 : 0.3461010456085205
Loss at iteration 150 : 0.4069846570491791
Loss at iteration 160 : 0.4265773594379425
Loss at iteration 170 : 0.4145205020904541
Loss at iteration 180 : 0.39022648334503174
Loss at iteration 10 : 0.3219526410102844
Loss at iteration 20 : 0.3965485095977783
Loss at iteration 30 : 0.46560007333755493
Loss at iteration 40 : 0.4093412160873413
Loss at iteration 50 : 0.3661036491394043
Loss at iteration 60 : 0.4254119396209717
Loss at iteration 70 : 0.44579043984413147
Loss at iteration 80 : 0.38698673248291016
Loss at iteration 90 : 0.3970063626766205
Loss at iteration 100 : 0.422568678855896
Loss at iteration 110 : 0.34380772709846497
Loss at iteration 120 : 0.3452287018299103
Loss at iteration 130 : 0.3912540078163147
Loss at iteration 140 : 0.42760029435157776
Loss at iteration 150 : 0.40192711353302
Loss at iteration 160 : 0.35239750146865845
Loss at iteration 170 : 0.3665998578071594
Loss at iteration 180 : 0.405201256275177
Loss at iteration 10 : 0.29822883009910583
Loss at iteration 20 : 0.4011085033416748
Loss at iteration 30 : 0.32220837473869324
Loss at iteration 40 : 0.352559894323349
Loss at iteration 50 : 0.3677349388599396
Loss at iteration 60 : 0.3308744728565216
Loss at iteration 70 : 0.42384132742881775
Loss at iteration 80 : 0.30520161986351013
Loss at iteration 90 : 0.35311073064804077
Loss at iteration 100 : 0.4342317283153534
Loss at iteration 110 : 0.4044285714626312
Loss at iteration 120 : 0.429609477519989
Loss at iteration 130 : 0.3994249403476715
Loss at iteration 140 : 0.37768200039863586
Loss at iteration 150 : 0.34876731038093567
Loss at iteration 160 : 0.35616564750671387
Loss at iteration 170 : 0.3847755789756775
Loss at iteration 180 : 0.4487038254737854
Loss at iteration 10 : 0.36290550231933594
Loss at iteration 20 : 0.4086889922618866
Loss at iteration 30 : 0.40610653162002563
Loss at iteration 40 : 0.34351569414138794
Loss at iteration 50 : 0.4152444899082184
Loss at iteration 60 : 0.3448505103588104
Loss at iteration 70 : 0.4226013720035553
Loss at iteration 80 : 0.46562308073043823
Loss at iteration 90 : 0.41489019989967346
Loss at iteration 100 : 0.43648073077201843
Loss at iteration 110 : 0.3601589798927307
Loss at iteration 120 : 0.3813483417034149
Loss at iteration 130 : 0.39307427406311035
Loss at iteration 140 : 0.37121933698654175
Loss at iteration 150 : 0.41292908787727356
Loss at iteration 160 : 0.35911786556243896
Loss at iteration 170 : 0.3192223906517029
Loss at iteration 180 : 0.39813852310180664
Loss at iteration 10 : 0.4298233389854431
Loss at iteration 20 : 0.33891409635543823
Loss at iteration 30 : 0.4362027049064636
Loss at iteration 40 : 0.40568721294403076
Loss at iteration 50 : 0.338219553232193
Loss at iteration 60 : 0.38376349210739136
Loss at iteration 70 : 0.3935619294643402
Loss at iteration 80 : 0.3941391706466675
Loss at iteration 90 : 0.48316076397895813
Loss at iteration 100 : 0.41312161087989807
Loss at iteration 110 : 0.3316946029663086
Loss at iteration 120 : 0.3140173852443695
Loss at iteration 130 : 0.3731759488582611
Loss at iteration 140 : 0.4061163067817688
Loss at iteration 150 : 0.4493563771247864
Loss at iteration 160 : 0.37825825810432434
Loss at iteration 170 : 0.2876768708229065
Loss at iteration 180 : 0.43056097626686096
Loss at iteration 10 : 0.3992725610733032
Loss at iteration 20 : 0.43848952651023865
Loss at iteration 30 : 0.46923986077308655
Loss at iteration 40 : 0.4278988838195801
Loss at iteration 50 : 0.4485299587249756
Loss at iteration 60 : 0.3508145809173584
Loss at iteration 70 : 0.38935765624046326
Loss at iteration 80 : 0.4070098102092743
Loss at iteration 90 : 0.3778320252895355
Loss at iteration 100 : 0.328683465719223
Loss at iteration 110 : 0.4384841322898865
Loss at iteration 120 : 0.3620492219924927
Loss at iteration 130 : 0.44317707419395447
Loss at iteration 140 : 0.4153475761413574
Loss at iteration 150 : 0.3502104580402374
Loss at iteration 160 : 0.45552510023117065
Loss at iteration 170 : 0.43356508016586304
Loss at iteration 180 : 0.42451947927474976
Loss at iteration 10 : 0.36112481355667114
Loss at iteration 20 : 0.4000471234321594
Loss at iteration 30 : 0.40975552797317505
Loss at iteration 40 : 0.29493018984794617
Loss at iteration 50 : 0.41972893476486206
Loss at iteration 60 : 0.37541019916534424
Loss at iteration 70 : 0.32131820917129517
Loss at iteration 80 : 0.34310925006866455
Loss at iteration 90 : 0.36158910393714905
Loss at iteration 100 : 0.38558876514434814
Loss at iteration 110 : 0.32935023307800293
Loss at iteration 120 : 0.3674277663230896
Loss at iteration 130 : 0.4205353260040283
Loss at iteration 140 : 0.35636675357818604
Loss at iteration 150 : 0.4081984758377075
Loss at iteration 160 : 0.3697666525840759
Loss at iteration 170 : 0.4412139356136322
Loss at iteration 180 : 0.37736886739730835
Loss at iteration 10 : 0.4986248016357422
Loss at iteration 20 : 0.4128260314464569
Loss at iteration 30 : 0.37937676906585693
Loss at iteration 40 : 0.31244587898254395
Loss at iteration 50 : 0.3519260883331299
Loss at iteration 60 : 0.3495541214942932
Loss at iteration 70 : 0.3508365750312805
Loss at iteration 80 : 0.3562343418598175
Loss at iteration 90 : 0.3237437307834625
Loss at iteration 100 : 0.4034684896469116
Loss at iteration 110 : 0.407956600189209
Loss at iteration 120 : 0.44198793172836304
Loss at iteration 130 : 0.3588793873786926
Loss at iteration 140 : 0.32949310541152954
Loss at iteration 150 : 0.35970354080200195
Loss at iteration 160 : 0.3514332175254822
Loss at iteration 170 : 0.33057230710983276
Loss at iteration 180 : 0.4658130407333374
Loss at iteration 10 : 0.3829631209373474
Loss at iteration 20 : 0.5244035124778748
Loss at iteration 30 : 0.403353750705719
Loss at iteration 40 : 0.40197300910949707
Loss at iteration 50 : 0.35574284195899963
Loss at iteration 60 : 0.3693866729736328
Loss at iteration 70 : 0.33452898263931274
Loss at iteration 80 : 0.43368425965309143
Loss at iteration 90 : 0.3579142689704895
Loss at iteration 100 : 0.4659503698348999
Loss at iteration 110 : 0.4109494686126709
Loss at iteration 120 : 0.3545306622982025
Loss at iteration 130 : 0.3680090308189392
Loss at iteration 140 : 0.33115190267562866
Loss at iteration 150 : 0.4236671030521393
Loss at iteration 160 : 0.4579164683818817
Loss at iteration 170 : 0.33100104331970215
Loss at iteration 180 : 0.4644840657711029
Loss at iteration 10 : 0.38653647899627686
Loss at iteration 20 : 0.5254361629486084
Loss at iteration 30 : 0.4315500855445862
Loss at iteration 40 : 0.35785961151123047
Loss at iteration 50 : 0.40993088483810425
Loss at iteration 60 : 0.39665141701698303
Loss at iteration 70 : 0.34584736824035645
Loss at iteration 80 : 0.376016229391098
Loss at iteration 90 : 0.3771589398384094
Loss at iteration 100 : 0.4037923812866211
Loss at iteration 110 : 0.3454703688621521
Loss at iteration 120 : 0.34068548679351807
Loss at iteration 130 : 0.3992273211479187
Loss at iteration 140 : 0.37305504083633423
Loss at iteration 150 : 0.40919262170791626
Loss at iteration 160 : 0.36808058619499207
Loss at iteration 170 : 0.38714611530303955
Loss at iteration 180 : 0.39350396394729614
Loss at iteration 10 : 0.3509538173675537
Loss at iteration 20 : 0.38211169838905334
Loss at iteration 30 : 0.35175198316574097
Loss at iteration 40 : 0.37783077359199524
Loss at iteration 50 : 0.3953499495983124
Loss at iteration 60 : 0.40398916602134705
Loss at iteration 70 : 0.4138885736465454
Loss at iteration 80 : 0.4136541485786438
Loss at iteration 90 : 0.31833234429359436
Loss at iteration 100 : 0.3544142544269562
Loss at iteration 110 : 0.4614654779434204
Loss at iteration 120 : 0.4162708520889282
Loss at iteration 130 : 0.45954787731170654
Loss at iteration 140 : 0.33877331018447876
Loss at iteration 150 : 0.395827978849411
Loss at iteration 160 : 0.42840686440467834
Loss at iteration 170 : 0.4030740559101105
Loss at iteration 180 : 0.3862723410129547
Loss at iteration 10 : 0.420162558555603
Loss at iteration 20 : 0.36337733268737793
Loss at iteration 30 : 0.45448383688926697
Loss at iteration 40 : 0.4033382534980774
Loss at iteration 50 : 0.4469951391220093
Loss at iteration 60 : 0.3715747594833374
Loss at iteration 70 : 0.374386727809906
Loss at iteration 80 : 0.33768391609191895
Loss at iteration 90 : 0.41791483759880066
Loss at iteration 100 : 0.3640137314796448
Loss at iteration 110 : 0.3182504177093506
Loss at iteration 120 : 0.38140958547592163
Loss at iteration 130 : 0.40744853019714355
Loss at iteration 140 : 0.3893509805202484
Loss at iteration 150 : 0.38880932331085205
Loss at iteration 160 : 0.35453930497169495
Loss at iteration 170 : 0.38157472014427185
Loss at iteration 180 : 0.35096192359924316
Loss at iteration 10 : 0.3936382532119751
Loss at iteration 20 : 0.33408617973327637
Loss at iteration 30 : 0.3281346559524536
Loss at iteration 40 : 0.423518568277359
Loss at iteration 50 : 0.40151599049568176
Loss at iteration 60 : 0.37956321239471436
Loss at iteration 70 : 0.34805914759635925
Loss at iteration 80 : 0.4108928442001343
Loss at iteration 90 : 0.32392051815986633
Loss at iteration 100 : 0.4069650173187256
Loss at iteration 110 : 0.32596132159233093
Loss at iteration 120 : 0.35375627875328064
Loss at iteration 130 : 0.3867812156677246
Loss at iteration 140 : 0.3918953537940979
Loss at iteration 150 : 0.3811790943145752
Loss at iteration 160 : 0.35785049200057983
Loss at iteration 170 : 0.37445729970932007
Loss at iteration 180 : 0.35274532437324524
Loss at iteration 10 : 0.4297829568386078
Loss at iteration 20 : 0.36408132314682007
Loss at iteration 30 : 0.36599093675613403
Loss at iteration 40 : 0.37921142578125
Loss at iteration 50 : 0.43125757575035095
Loss at iteration 60 : 0.3184874653816223
Loss at iteration 70 : 0.33406543731689453
Loss at iteration 80 : 0.31393417716026306
Loss at iteration 90 : 0.46542564034461975
Loss at iteration 100 : 0.4869598150253296
Loss at iteration 110 : 0.34821897745132446
Loss at iteration 120 : 0.3611550033092499
Loss at iteration 130 : 0.3415578007698059
Loss at iteration 140 : 0.41154637932777405
Loss at iteration 150 : 0.3521776497364044
Loss at iteration 160 : 0.36997535824775696
Loss at iteration 170 : 0.3884802460670471
Loss at iteration 180 : 0.3425193428993225
Loss at iteration 10 : 0.35173261165618896
Loss at iteration 20 : 0.3658484220504761
Loss at iteration 30 : 0.37429729104042053
Loss at iteration 40 : 0.38014817237854004
Loss at iteration 50 : 0.3889766335487366
Loss at iteration 60 : 0.4284454882144928
Loss at iteration 70 : 0.3753671646118164
Loss at iteration 80 : 0.3594955801963806
Loss at iteration 90 : 0.39971134066581726
Loss at iteration 100 : 0.40100497007369995
Loss at iteration 110 : 0.3109145164489746
Loss at iteration 120 : 0.4116244912147522
Loss at iteration 130 : 0.3894074559211731
Loss at iteration 140 : 0.3272491693496704
Loss at iteration 150 : 0.40603184700012207
Loss at iteration 160 : 0.4393559694290161
Loss at iteration 170 : 0.3445473611354828
Loss at iteration 180 : 0.4860270321369171
Loss at iteration 10 : 0.2944788932800293
Loss at iteration 20 : 0.35615161061286926
Loss at iteration 30 : 0.3392922878265381
Loss at iteration 40 : 0.4207409620285034
Loss at iteration 50 : 0.41640934348106384
Loss at iteration 60 : 0.3775019943714142
Loss at iteration 70 : 0.3899950385093689
Loss at iteration 80 : 0.4061831533908844
Loss at iteration 90 : 0.3827474117279053
Loss at iteration 100 : 0.38402271270751953
Loss at iteration 110 : 0.37510162591934204
Loss at iteration 120 : 0.38729166984558105
Loss at iteration 130 : 0.37148576974868774
Loss at iteration 140 : 0.40599486231803894
Loss at iteration 150 : 0.3726150393486023
Loss at iteration 160 : 0.3661227226257324
Loss at iteration 170 : 0.36674654483795166
Loss at iteration 180 : 0.4673871397972107
Loss at iteration 10 : 0.415850967168808
Loss at iteration 20 : 0.3683805465698242
Loss at iteration 30 : 0.3715742230415344
Loss at iteration 40 : 0.34499478340148926
Loss at iteration 50 : 0.3821631669998169
Loss at iteration 60 : 0.42493176460266113
Loss at iteration 70 : 0.3640553951263428
Loss at iteration 80 : 0.28683799505233765
Loss at iteration 90 : 0.503887414932251
Loss at iteration 100 : 0.3438118100166321
Loss at iteration 110 : 0.3468609154224396
Loss at iteration 120 : 0.38148045539855957
Loss at iteration 130 : 0.34705254435539246
Loss at iteration 140 : 0.43256109952926636
Loss at iteration 150 : 0.4062374234199524
Loss at iteration 160 : 0.3611449599266052
Loss at iteration 170 : 0.3942829668521881
Loss at iteration 180 : 0.41911935806274414
Loss at iteration 10 : 0.4467661380767822
Loss at iteration 20 : 0.48545247316360474
Loss at iteration 30 : 0.3585304021835327
Loss at iteration 40 : 0.39454710483551025
Loss at iteration 50 : 0.43005430698394775
Loss at iteration 60 : 0.3602678179740906
Loss at iteration 70 : 0.3035711646080017
Loss at iteration 80 : 0.37821531295776367
Loss at iteration 90 : 0.4088928997516632
Loss at iteration 100 : 0.44423460960388184
Loss at iteration 110 : 0.3247565031051636
Loss at iteration 120 : 0.3507513999938965
Loss at iteration 130 : 0.4015081822872162
Loss at iteration 140 : 0.44398385286331177
Loss at iteration 150 : 0.45462676882743835
Loss at iteration 160 : 0.42421954870224
Loss at iteration 170 : 0.39931100606918335
Loss at iteration 180 : 0.3334672451019287
Loss at iteration 10 : 0.3689035177230835
Loss at iteration 20 : 0.375993937253952
Loss at iteration 30 : 0.35887810587882996
Loss at iteration 40 : 0.3619648814201355
Loss at iteration 50 : 0.3439929783344269
Loss at iteration 60 : 0.3651960790157318
Loss at iteration 70 : 0.40251392126083374
Loss at iteration 80 : 0.3554528057575226
Loss at iteration 90 : 0.39291781187057495
Loss at iteration 100 : 0.38213175535202026
Loss at iteration 110 : 0.3479868173599243
Loss at iteration 120 : 0.34568461775779724
Loss at iteration 130 : 0.3325141668319702
Loss at iteration 140 : 0.3481390178203583
Loss at iteration 150 : 0.3271411955356598
Loss at iteration 160 : 0.28055229783058167
Loss at iteration 170 : 0.4239738881587982
Loss at iteration 180 : 0.39359331130981445
Loss at iteration 10 : 0.36801034212112427
Loss at iteration 20 : 0.45671719312667847
Loss at iteration 30 : 0.3778384029865265
Loss at iteration 40 : 0.38090136647224426
Loss at iteration 50 : 0.4324651062488556
Loss at iteration 60 : 0.45597898960113525
Loss at iteration 70 : 0.3718399405479431
Loss at iteration 80 : 0.4507485330104828
Loss at iteration 90 : 0.4149281084537506
Loss at iteration 100 : 0.3365137577056885
Loss at iteration 110 : 0.3927695155143738
Loss at iteration 120 : 0.35854780673980713
Loss at iteration 130 : 0.37059128284454346
Loss at iteration 140 : 0.4299275875091553
Loss at iteration 150 : 0.3070310950279236
Loss at iteration 160 : 0.333614706993103
Loss at iteration 170 : 0.40521568059921265
Loss at iteration 180 : 0.3431706428527832
Loss at iteration 10 : 0.3448665738105774
Loss at iteration 20 : 0.36062172055244446
Loss at iteration 30 : 0.33418935537338257
Loss at iteration 40 : 0.38718825578689575
Loss at iteration 50 : 0.392314612865448
Loss at iteration 60 : 0.39146876335144043
Loss at iteration 70 : 0.400570273399353
Loss at iteration 80 : 0.323039174079895
Loss at iteration 90 : 0.30328673124313354
Loss at iteration 100 : 0.3558565378189087
Loss at iteration 110 : 0.4281761348247528
Loss at iteration 120 : 0.4382244348526001
Loss at iteration 130 : 0.3897177577018738
Loss at iteration 140 : 0.37974321842193604
Loss at iteration 150 : 0.3179789185523987
Loss at iteration 160 : 0.35104137659072876
Loss at iteration 170 : 0.3510969579219818
Loss at iteration 180 : 0.4083769619464874
Loss at iteration 10 : 0.377593457698822
Loss at iteration 20 : 0.3991171717643738
Loss at iteration 30 : 0.38680171966552734
Loss at iteration 40 : 0.3784443736076355
Loss at iteration 50 : 0.34465697407722473
Loss at iteration 60 : 0.32678312063217163
Loss at iteration 70 : 0.3528004586696625
Loss at iteration 80 : 0.3912007212638855
Loss at iteration 90 : 0.40919023752212524
Loss at iteration 100 : 0.3590056598186493
Loss at iteration 110 : 0.36110153794288635
Loss at iteration 120 : 0.3412919342517853
Loss at iteration 130 : 0.3708499073982239
Loss at iteration 140 : 0.34642285108566284
Loss at iteration 150 : 0.3308091163635254
Loss at iteration 160 : 0.3004275858402252
Loss at iteration 170 : 0.36100244522094727
Loss at iteration 180 : 0.4366048574447632
Loss at iteration 10 : 0.3879085183143616
Loss at iteration 20 : 0.3422527313232422
Loss at iteration 30 : 0.3865005373954773
Loss at iteration 40 : 0.29211515188217163
Loss at iteration 50 : 0.3698084354400635
Loss at iteration 60 : 0.4889013171195984
Loss at iteration 70 : 0.3317737877368927
Loss at iteration 80 : 0.3435957133769989
Loss at iteration 90 : 0.36756035685539246
Loss at iteration 100 : 0.39574533700942993
Loss at iteration 110 : 0.3393203616142273
Loss at iteration 120 : 0.341807097196579
Loss at iteration 130 : 0.43489187955856323
Loss at iteration 140 : 0.46604281663894653
Loss at iteration 150 : 0.3656507134437561
Loss at iteration 160 : 0.3687342703342438
Loss at iteration 170 : 0.39160364866256714
Loss at iteration 180 : 0.4424368143081665
Loss at iteration 10 : 0.3258780539035797
Loss at iteration 20 : 0.4709770679473877
Loss at iteration 30 : 0.4263148009777069
Loss at iteration 40 : 0.4820343852043152
Loss at iteration 50 : 0.3652269244194031
Loss at iteration 60 : 0.4417768120765686
Loss at iteration 70 : 0.41650035977363586
Loss at iteration 80 : 0.39400237798690796
Loss at iteration 90 : 0.3920556604862213
Loss at iteration 100 : 0.37002766132354736
Loss at iteration 110 : 0.34659165143966675
Loss at iteration 120 : 0.4069560766220093
Loss at iteration 130 : 0.3534672260284424
Loss at iteration 140 : 0.3160129189491272
Loss at iteration 150 : 0.4333307147026062
Loss at iteration 160 : 0.33551377058029175
Loss at iteration 170 : 0.41165828704833984
Loss at iteration 180 : 0.41163551807403564
Loss at iteration 10 : 0.3054390251636505
Loss at iteration 20 : 0.338444322347641
Loss at iteration 30 : 0.338407963514328
Loss at iteration 40 : 0.4343332052230835
Loss at iteration 50 : 0.30086758732795715
Loss at iteration 60 : 0.40201535820961
Loss at iteration 70 : 0.335364431142807
Loss at iteration 80 : 0.41577693819999695
Loss at iteration 90 : 0.35969436168670654
Loss at iteration 100 : 0.3797275424003601
Loss at iteration 110 : 0.38502535223960876
Loss at iteration 120 : 0.29184412956237793
Loss at iteration 130 : 0.3967844545841217
Loss at iteration 140 : 0.4049331247806549
Loss at iteration 150 : 0.38707292079925537
Loss at iteration 160 : 0.37803974747657776
Loss at iteration 170 : 0.38243889808654785
Loss at iteration 180 : 0.4122539162635803
Loss at iteration 10 : 0.40058666467666626
Loss at iteration 20 : 0.34396374225616455
Loss at iteration 30 : 0.3884384036064148
Loss at iteration 40 : 0.3690401017665863
Loss at iteration 50 : 0.2944532334804535
Loss at iteration 60 : 0.34713539481163025
Loss at iteration 70 : 0.35384035110473633
Loss at iteration 80 : 0.3673398494720459
Loss at iteration 90 : 0.3063885271549225
Loss at iteration 100 : 0.33123353123664856
Loss at iteration 110 : 0.3602680563926697
Loss at iteration 120 : 0.40353506803512573
Loss at iteration 130 : 0.4052431583404541
Loss at iteration 140 : 0.39426812529563904
Loss at iteration 150 : 0.343437522649765
Loss at iteration 160 : 0.3018728494644165
Loss at iteration 170 : 0.42202624678611755
Loss at iteration 180 : 0.35333579778671265
Loss at iteration 10 : 0.315889835357666
Loss at iteration 20 : 0.3908354640007019
Loss at iteration 30 : 0.3677181005477905
Loss at iteration 40 : 0.3841751515865326
Loss at iteration 50 : 0.47379982471466064
Loss at iteration 60 : 0.33515357971191406
Loss at iteration 70 : 0.38295242190361023
Loss at iteration 80 : 0.4641382694244385
Loss at iteration 90 : 0.35785648226737976
Loss at iteration 100 : 0.445942759513855
Loss at iteration 110 : 0.3952157497406006
Loss at iteration 120 : 0.4259943664073944
Loss at iteration 130 : 0.39088431000709534
Loss at iteration 140 : 0.39854177832603455
Loss at iteration 150 : 0.36395224928855896
Loss at iteration 160 : 0.47435522079467773
Loss at iteration 170 : 0.3591306507587433
Loss at iteration 180 : 0.3543352484703064
Loss at iteration 10 : 0.3183448314666748
Loss at iteration 20 : 0.3444242775440216
Loss at iteration 30 : 0.3820437788963318
Loss at iteration 40 : 0.39798784255981445
Loss at iteration 50 : 0.2977144420146942
Loss at iteration 60 : 0.3590371608734131
Loss at iteration 70 : 0.3656063675880432
Loss at iteration 80 : 0.3916596472263336
Loss at iteration 90 : 0.33573153614997864
Loss at iteration 100 : 0.36412549018859863
Loss at iteration 110 : 0.3778458833694458
Loss at iteration 120 : 0.3905876576900482
Loss at iteration 130 : 0.46316301822662354
Loss at iteration 140 : 0.41476666927337646
Loss at iteration 150 : 0.354060560464859
Loss at iteration 160 : 0.38187068700790405
Loss at iteration 170 : 0.31284135580062866
Loss at iteration 180 : 0.34613412618637085
Loss at iteration 10 : 0.4650420546531677
Loss at iteration 20 : 0.32333073019981384
Loss at iteration 30 : 0.3141871988773346
Loss at iteration 40 : 0.385982483625412
Loss at iteration 50 : 0.45246341824531555
Loss at iteration 60 : 0.38733911514282227
Loss at iteration 70 : 0.3062185049057007
Loss at iteration 80 : 0.34936386346817017
Loss at iteration 90 : 0.478452205657959
Loss at iteration 100 : 0.40062209963798523
Loss at iteration 110 : 0.3675292134284973
Loss at iteration 120 : 0.3687151372432709
Loss at iteration 130 : 0.32984188199043274
Loss at iteration 140 : 0.3636590540409088
Loss at iteration 150 : 0.5239114165306091
Loss at iteration 160 : 0.4488212466239929
Loss at iteration 170 : 0.3450004458427429
Loss at iteration 180 : 0.33470475673675537
Loss at iteration 10 : 0.4168780446052551
Loss at iteration 20 : 0.3807682394981384
Loss at iteration 30 : 0.32132846117019653
Loss at iteration 40 : 0.36554592847824097
Loss at iteration 50 : 0.3866247534751892
Loss at iteration 60 : 0.4490872025489807
Loss at iteration 70 : 0.3513195812702179
Loss at iteration 80 : 0.3938871920108795
Loss at iteration 90 : 0.3626782298088074
Loss at iteration 100 : 0.38577985763549805
Loss at iteration 110 : 0.36672458052635193
Loss at iteration 120 : 0.4945705533027649
Loss at iteration 130 : 0.43522578477859497
Loss at iteration 140 : 0.46161073446273804
Loss at iteration 150 : 0.41320234537124634
Loss at iteration 160 : 0.4113084077835083
Loss at iteration 170 : 0.3708777129650116
Loss at iteration 180 : 0.33711671829223633
Loss at iteration 10 : 0.32974833250045776
Loss at iteration 20 : 0.3786046504974365
Loss at iteration 30 : 0.33247047662734985
Loss at iteration 40 : 0.3815745711326599
Loss at iteration 50 : 0.3447621762752533
Loss at iteration 60 : 0.3547515869140625
Loss at iteration 70 : 0.39874696731567383
Loss at iteration 80 : 0.39075231552124023
Loss at iteration 90 : 0.3813480734825134
Loss at iteration 100 : 0.3825153708457947
Loss at iteration 110 : 0.36500197649002075
Loss at iteration 120 : 0.4003635048866272
Loss at iteration 130 : 0.3964427709579468
Loss at iteration 140 : 0.4436946511268616
Loss at iteration 150 : 0.4240334630012512
Loss at iteration 160 : 0.38068729639053345
Loss at iteration 170 : 0.4103052616119385
Loss at iteration 180 : 0.43209031224250793
Loss at iteration 10 : 0.41823554039001465
Loss at iteration 20 : 0.321872353553772
Loss at iteration 30 : 0.4192928969860077
Loss at iteration 40 : 0.3577435314655304
Loss at iteration 50 : 0.41583889722824097
Loss at iteration 60 : 0.3370002806186676
Loss at iteration 70 : 0.358562171459198
Loss at iteration 80 : 0.3158591687679291
Loss at iteration 90 : 0.3491751551628113
Loss at iteration 100 : 0.3930116891860962
Loss at iteration 110 : 0.4499567747116089
Loss at iteration 120 : 0.3656817674636841
Loss at iteration 130 : 0.3684624135494232
Loss at iteration 140 : 0.4296669363975525
Loss at iteration 150 : 0.35169142484664917
Loss at iteration 160 : 0.3926819860935211
Loss at iteration 170 : 0.36540454626083374
Loss at iteration 180 : 0.418256938457489
Loss at iteration 10 : 0.3751000761985779
Loss at iteration 20 : 0.3615349531173706
Loss at iteration 30 : 0.35244929790496826
Loss at iteration 40 : 0.3834667205810547
Loss at iteration 50 : 0.45314472913742065
Loss at iteration 60 : 0.4026303291320801
Loss at iteration 70 : 0.34039199352264404
Loss at iteration 80 : 0.3600095510482788
Loss at iteration 90 : 0.367716521024704
Loss at iteration 100 : 0.2697727084159851
Loss at iteration 110 : 0.422348290681839
Loss at iteration 120 : 0.33299845457077026
Loss at iteration 130 : 0.3681519627571106
Loss at iteration 140 : 0.3717890977859497
Loss at iteration 150 : 0.32924002408981323
Loss at iteration 160 : 0.3791077435016632
Loss at iteration 170 : 0.40062928199768066
Loss at iteration 180 : 0.3545563519001007
Loss at iteration 10 : 0.3162522315979004
Loss at iteration 20 : 0.40258681774139404
Loss at iteration 30 : 0.40851065516471863
Loss at iteration 40 : 0.3714572787284851
Loss at iteration 50 : 0.3324352502822876
Loss at iteration 60 : 0.421988308429718
Loss at iteration 70 : 0.3110794126987457
Loss at iteration 80 : 0.42109212279319763
Loss at iteration 90 : 0.369623064994812
Loss at iteration 100 : 0.38369426131248474
Loss at iteration 110 : 0.36636632680892944
Loss at iteration 120 : 0.34486517310142517
Loss at iteration 130 : 0.3654365539550781
Loss at iteration 140 : 0.3675379753112793
Loss at iteration 150 : 0.3378971219062805
Loss at iteration 160 : 0.41746094822883606
Loss at iteration 170 : 0.29812750220298767
Loss at iteration 180 : 0.41771644353866577
Loss at iteration 10 : 0.44072964787483215
Loss at iteration 20 : 0.3316322863101959
Loss at iteration 30 : 0.3678320646286011
Loss at iteration 40 : 0.42251747846603394
Loss at iteration 50 : 0.3656153380870819
Loss at iteration 60 : 0.3562043309211731
Loss at iteration 70 : 0.3885228633880615
Loss at iteration 80 : 0.37130415439605713
Loss at iteration 90 : 0.38649603724479675
Loss at iteration 100 : 0.33205240964889526
Loss at iteration 110 : 0.3563157320022583
Loss at iteration 120 : 0.3500639796257019
Loss at iteration 130 : 0.40654927492141724
Loss at iteration 140 : 0.3753816485404968
Loss at iteration 150 : 0.382489949464798
Loss at iteration 160 : 0.3916271924972534
Loss at iteration 170 : 0.4034664034843445
Loss at iteration 180 : 0.30864575505256653
Loss at iteration 10 : 0.4416196048259735
Loss at iteration 20 : 0.3636026382446289
Loss at iteration 30 : 0.3989984095096588
Loss at iteration 40 : 0.34699055552482605
Loss at iteration 50 : 0.3822053372859955
Loss at iteration 60 : 0.36736083030700684
Loss at iteration 70 : 0.34199753403663635
Loss at iteration 80 : 0.35646316409111023
Loss at iteration 90 : 0.3536217212677002
Loss at iteration 100 : 0.39284688234329224
Loss at iteration 110 : 0.4152565896511078
Loss at iteration 120 : 0.37271493673324585
Loss at iteration 130 : 0.4123880863189697
Loss at iteration 140 : 0.3831411302089691
Loss at iteration 150 : 0.37367480993270874
Loss at iteration 160 : 0.47592151165008545
Loss at iteration 170 : 0.32042449712753296
Loss at iteration 180 : 0.37382322549819946
Loss at iteration 10 : 0.40084314346313477
Loss at iteration 20 : 0.3589143753051758
Loss at iteration 30 : 0.38315296173095703
Loss at iteration 40 : 0.36375439167022705
Loss at iteration 50 : 0.36476898193359375
Loss at iteration 60 : 0.4010149836540222
Loss at iteration 70 : 0.3924444615840912
Loss at iteration 80 : 0.34270358085632324
Loss at iteration 90 : 0.3621547818183899
Loss at iteration 100 : 0.36853355169296265
Loss at iteration 110 : 0.480615496635437
Loss at iteration 120 : 0.3725995719432831
Loss at iteration 130 : 0.4043113589286804
Loss at iteration 140 : 0.39464154839515686
Loss at iteration 150 : 0.40636637806892395
Loss at iteration 160 : 0.40759599208831787
Loss at iteration 170 : 0.4098900258541107
Loss at iteration 180 : 0.4236900806427002
Loss at iteration 10 : 0.40408480167388916
Loss at iteration 20 : 0.38807523250579834
Loss at iteration 30 : 0.4623381793498993
Loss at iteration 40 : 0.3626006543636322
Loss at iteration 50 : 0.3617348074913025
Loss at iteration 60 : 0.34068727493286133
Loss at iteration 70 : 0.3285595774650574
Loss at iteration 80 : 0.41933178901672363
Loss at iteration 90 : 0.3720654249191284
Loss at iteration 100 : 0.4758702218532562
Loss at iteration 110 : 0.39380085468292236
Loss at iteration 120 : 0.33066079020500183
Loss at iteration 130 : 0.4210380017757416
Loss at iteration 140 : 0.3954472839832306
Loss at iteration 150 : 0.3057083785533905
Loss at iteration 160 : 0.4047977328300476
Loss at iteration 170 : 0.36314040422439575
Loss at iteration 180 : 0.3771870732307434
Loss at iteration 10 : 0.4002367854118347
Loss at iteration 20 : 0.42021721601486206
Loss at iteration 30 : 0.4097592234611511
Loss at iteration 40 : 0.39510810375213623
Loss at iteration 50 : 0.3844130039215088
Loss at iteration 60 : 0.3366988003253937
Loss at iteration 70 : 0.45775967836380005
Loss at iteration 80 : 0.36321890354156494
Loss at iteration 90 : 0.38731053471565247
Loss at iteration 100 : 0.35643085837364197
Loss at iteration 110 : 0.3397907018661499
Loss at iteration 120 : 0.42094746232032776
Loss at iteration 130 : 0.42841240763664246
Loss at iteration 140 : 0.3706163167953491
Loss at iteration 150 : 0.4422738254070282
Loss at iteration 160 : 0.38990533351898193
Loss at iteration 170 : 0.34408241510391235
Loss at iteration 180 : 0.42042046785354614
Loss at iteration 10 : 0.36704203486442566
Loss at iteration 20 : 0.3413093686103821
Loss at iteration 30 : 0.34385186433792114
Loss at iteration 40 : 0.37779197096824646
Loss at iteration 50 : 0.37900909781455994
Loss at iteration 60 : 0.23188969492912292
Loss at iteration 70 : 0.36692357063293457
Loss at iteration 80 : 0.3381599485874176
Loss at iteration 90 : 0.35398054122924805
Loss at iteration 100 : 0.338255375623703
Loss at iteration 110 : 0.3770155906677246
Loss at iteration 120 : 0.36014440655708313
Loss at iteration 130 : 0.3467645049095154
Loss at iteration 140 : 0.3941000699996948
Loss at iteration 150 : 0.3858892023563385
Loss at iteration 160 : 0.42595338821411133
Loss at iteration 170 : 0.3666754364967346
Loss at iteration 180 : 0.3742651641368866
Loss at iteration 10 : 0.37016820907592773
Loss at iteration 20 : 0.3618834316730499
Loss at iteration 30 : 0.345001220703125
Loss at iteration 40 : 0.3638608753681183
Loss at iteration 50 : 0.3897266983985901
Loss at iteration 60 : 0.40008634328842163
Loss at iteration 70 : 0.36297473311424255
Loss at iteration 80 : 0.34851545095443726
Loss at iteration 90 : 0.42978435754776
Loss at iteration 100 : 0.3326914608478546
Loss at iteration 110 : 0.4133823812007904
Loss at iteration 120 : 0.3809913992881775
Loss at iteration 130 : 0.4454076290130615
Loss at iteration 140 : 0.3978547751903534
Loss at iteration 150 : 0.32205596566200256
Loss at iteration 160 : 0.3711620569229126
Loss at iteration 170 : 0.44910722970962524
Loss at iteration 180 : 0.47753816843032837
Loss at iteration 10 : 0.3937148153781891
Loss at iteration 20 : 0.33636853098869324
Loss at iteration 30 : 0.3845308721065521
Loss at iteration 40 : 0.4026440680027008
Loss at iteration 50 : 0.4590687155723572
Loss at iteration 60 : 0.32009434700012207
Loss at iteration 70 : 0.2718736231327057
Loss at iteration 80 : 0.3520599603652954
Loss at iteration 90 : 0.42672985792160034
Loss at iteration 100 : 0.2947827875614166
Loss at iteration 110 : 0.38636642694473267
Loss at iteration 120 : 0.34164953231811523
Loss at iteration 130 : 0.3639380931854248
Loss at iteration 140 : 0.4158693253993988
Loss at iteration 150 : 0.36536628007888794
Loss at iteration 160 : 0.40131622552871704
Loss at iteration 170 : 0.3773428201675415
Loss at iteration 180 : 0.46793657541275024
Loss at iteration 10 : 0.3842245042324066
Loss at iteration 20 : 0.36597752571105957
Loss at iteration 30 : 0.33297285437583923
Loss at iteration 40 : 0.4368170201778412
Loss at iteration 50 : 0.40216055512428284
Loss at iteration 60 : 0.3647293448448181
Loss at iteration 70 : 0.33501893281936646
Loss at iteration 80 : 0.346801221370697
Loss at iteration 90 : 0.42347776889801025
Loss at iteration 100 : 0.38972193002700806
Loss at iteration 110 : 0.37700730562210083
Loss at iteration 120 : 0.3259824216365814
Loss at iteration 130 : 0.43438974022865295
Loss at iteration 140 : 0.37291139364242554
Loss at iteration 150 : 0.5018965005874634
Loss at iteration 160 : 0.4397650957107544
Loss at iteration 170 : 0.36510419845581055
Loss at iteration 180 : 0.37047070264816284
Loss at iteration 10 : 0.4447258710861206
Loss at iteration 20 : 0.5129780769348145
Loss at iteration 30 : 0.44653844833374023
Loss at iteration 40 : 0.34439918398857117
Loss at iteration 50 : 0.3348057270050049
Loss at iteration 60 : 0.38730281591415405
Loss at iteration 70 : 0.36309224367141724
Loss at iteration 80 : 0.446490079164505
Loss at iteration 90 : 0.38940414786338806
Loss at iteration 100 : 0.3752601742744446
Loss at iteration 110 : 0.4026474952697754
Loss at iteration 120 : 0.36700499057769775
Loss at iteration 130 : 0.33472713828086853
Loss at iteration 140 : 0.38457924127578735
Loss at iteration 150 : 0.3395708501338959
Loss at iteration 160 : 0.35111135244369507
Loss at iteration 170 : 0.3936777114868164
Loss at iteration 180 : 0.3074897527694702
Loss at iteration 10 : 0.30940595269203186
Loss at iteration 20 : 0.37813979387283325
Loss at iteration 30 : 0.3881617486476898
Loss at iteration 40 : 0.42953959107398987
Loss at iteration 50 : 0.3720882534980774
Loss at iteration 60 : 0.3267209529876709
Loss at iteration 70 : 0.3740062117576599
Loss at iteration 80 : 0.33840411901474
Loss at iteration 90 : 0.4184366464614868
Loss at iteration 100 : 0.40322089195251465
Loss at iteration 110 : 0.4261592924594879
Loss at iteration 120 : 0.34047025442123413
Loss at iteration 130 : 0.36349305510520935
Loss at iteration 140 : 0.387297123670578
Loss at iteration 150 : 0.4046671390533447
Loss at iteration 160 : 0.263742059469223
Loss at iteration 170 : 0.34811070561408997
Loss at iteration 180 : 0.413801372051239
Loss at iteration 10 : 0.40201422572135925
Loss at iteration 20 : 0.3167228102684021
Loss at iteration 30 : 0.38716715574264526
Loss at iteration 40 : 0.4033214747905731
Loss at iteration 50 : 0.3580673336982727
Loss at iteration 60 : 0.29442915320396423
Loss at iteration 70 : 0.36267396807670593
Loss at iteration 80 : 0.3901197016239166
Loss at iteration 90 : 0.3587265610694885
Loss at iteration 100 : 0.34744012355804443
Loss at iteration 110 : 0.4300452768802643
Loss at iteration 120 : 0.3762994408607483
Loss at iteration 130 : 0.33320876955986023
Loss at iteration 140 : 0.38484758138656616
Loss at iteration 150 : 0.3939071297645569
Loss at iteration 160 : 0.3500187397003174
Loss at iteration 170 : 0.36083340644836426
Loss at iteration 180 : 0.45500993728637695
Loss at iteration 10 : 0.3395249843597412
Loss at iteration 20 : 0.41224679350852966
Loss at iteration 30 : 0.4229380786418915
Loss at iteration 40 : 0.32209649682044983
Loss at iteration 50 : 0.35714590549468994
Loss at iteration 60 : 0.33694660663604736
Loss at iteration 70 : 0.3341028690338135
Loss at iteration 80 : 0.39900606870651245
Loss at iteration 90 : 0.38100796937942505
Loss at iteration 100 : 0.41110989451408386
Loss at iteration 110 : 0.4104735255241394
Loss at iteration 120 : 0.36444658041000366
Loss at iteration 130 : 0.4630972743034363
Loss at iteration 140 : 0.4054241478443146
Loss at iteration 150 : 0.36351144313812256
Loss at iteration 160 : 0.3473096489906311
Loss at iteration 170 : 0.4721197783946991
Loss at iteration 180 : 0.34407544136047363
Loss at iteration 10 : 0.3704715967178345
Loss at iteration 20 : 0.40932780504226685
Loss at iteration 30 : 0.37572500109672546
Loss at iteration 40 : 0.35569512844085693
Loss at iteration 50 : 0.33895793557167053
Loss at iteration 60 : 0.31800955533981323
Loss at iteration 70 : 0.40014827251434326
Loss at iteration 80 : 0.38827216625213623
Loss at iteration 90 : 0.29938048124313354
Loss at iteration 100 : 0.36177340149879456
Loss at iteration 110 : 0.39619433879852295
Loss at iteration 120 : 0.41906028985977173
Loss at iteration 130 : 0.414114385843277
Loss at iteration 140 : 0.49564701318740845
Loss at iteration 150 : 0.37895166873931885
Loss at iteration 160 : 0.33833077549934387
Loss at iteration 170 : 0.38020628690719604
Loss at iteration 180 : 0.505738377571106
Loss at iteration 10 : 0.4072342813014984
Loss at iteration 20 : 0.42674872279167175
Loss at iteration 30 : 0.3703911304473877
Loss at iteration 40 : 0.3900488018989563
Loss at iteration 50 : 0.3343519866466522
Loss at iteration 60 : 0.3592546284198761
Loss at iteration 70 : 0.3200516700744629
Loss at iteration 80 : 0.457550585269928
Loss at iteration 90 : 0.382041871547699
Loss at iteration 100 : 0.40429481863975525
Loss at iteration 110 : 0.43012845516204834
Loss at iteration 120 : 0.38063567876815796
Loss at iteration 130 : 0.36002177000045776
Loss at iteration 140 : 0.37805601954460144
Loss at iteration 150 : 0.36734527349472046
Loss at iteration 160 : 0.3045431077480316
Loss at iteration 170 : 0.49953171610832214
Loss at iteration 180 : 0.3994412422180176
Loss at iteration 10 : 0.34630176424980164
Loss at iteration 20 : 0.43872740864753723
Loss at iteration 30 : 0.33217188715934753
Loss at iteration 40 : 0.3689250946044922
Loss at iteration 50 : 0.38661566376686096
Loss at iteration 60 : 0.336790531873703
Loss at iteration 70 : 0.34860390424728394
Loss at iteration 80 : 0.30421799421310425
Loss at iteration 90 : 0.3415084481239319
Loss at iteration 100 : 0.3494037985801697
Loss at iteration 110 : 0.4531031548976898
Loss at iteration 120 : 0.42702409625053406
Loss at iteration 130 : 0.35843855142593384
Loss at iteration 140 : 0.4663631319999695
Loss at iteration 150 : 0.4354090094566345
Loss at iteration 160 : 0.39246588945388794
Loss at iteration 170 : 0.37481942772865295
Loss at iteration 180 : 0.36906522512435913
Loss at iteration 10 : 0.4111047387123108
Loss at iteration 20 : 0.37908685207366943
Loss at iteration 30 : 0.36299818754196167
Loss at iteration 40 : 0.3569616675376892
Loss at iteration 50 : 0.3596069812774658
Loss at iteration 60 : 0.4112265110015869
Loss at iteration 70 : 0.3365592360496521
Loss at iteration 80 : 0.34764227271080017
Loss at iteration 90 : 0.3724883198738098
Loss at iteration 100 : 0.3962935209274292
Loss at iteration 110 : 0.4195104241371155
Loss at iteration 120 : 0.3728136420249939
Loss at iteration 130 : 0.37500205636024475
Loss at iteration 140 : 0.35767054557800293
Loss at iteration 150 : 0.41934311389923096
Loss at iteration 160 : 0.4512020945549011
Loss at iteration 170 : 0.39742904901504517
Loss at iteration 180 : 0.2869483232498169
Loss at iteration 10 : 0.39311331510543823
Loss at iteration 20 : 0.4130401313304901
Loss at iteration 30 : 0.31988149881362915
Loss at iteration 40 : 0.3924831449985504
Loss at iteration 50 : 0.4435620605945587
Loss at iteration 60 : 0.4022182822227478
Loss at iteration 70 : 0.37266409397125244
Loss at iteration 80 : 0.34855416417121887
Loss at iteration 90 : 0.3374169170856476
Loss at iteration 100 : 0.43159177899360657
Loss at iteration 110 : 0.35468411445617676
Loss at iteration 120 : 0.3856779932975769
Loss at iteration 130 : 0.3777512013912201
Loss at iteration 140 : 0.38591206073760986
Loss at iteration 150 : 0.33225470781326294
Loss at iteration 160 : 0.4035823345184326
Loss at iteration 170 : 0.42646515369415283
Loss at iteration 180 : 0.3761863708496094
Loss at iteration 10 : 0.4105645418167114
Loss at iteration 20 : 0.3385522663593292
Loss at iteration 30 : 0.3476196229457855
Loss at iteration 40 : 0.41174572706222534
Loss at iteration 50 : 0.336855411529541
Loss at iteration 60 : 0.3394264280796051
Loss at iteration 70 : 0.3452244997024536
Loss at iteration 80 : 0.38540396094322205
Loss at iteration 90 : 0.4109976887702942
Loss at iteration 100 : 0.39257633686065674
Loss at iteration 110 : 0.33967143297195435
Loss at iteration 120 : 0.397579550743103
Loss at iteration 130 : 0.36305686831474304
Loss at iteration 140 : 0.3296549916267395
Loss at iteration 150 : 0.417479932308197
Loss at iteration 160 : 0.33038589358329773
Loss at iteration 170 : 0.42560404539108276
Loss at iteration 180 : 0.4601147770881653
Loss at iteration 10 : 0.36857736110687256
Loss at iteration 20 : 0.44899845123291016
Loss at iteration 30 : 0.3120909035205841
Loss at iteration 40 : 0.374370276927948
Loss at iteration 50 : 0.3596741557121277
Loss at iteration 60 : 0.39229387044906616
Loss at iteration 70 : 0.46273159980773926
Loss at iteration 80 : 0.36588340997695923
Loss at iteration 90 : 0.4187920093536377
Loss at iteration 100 : 0.47662657499313354
Loss at iteration 110 : 0.4447595179080963
Loss at iteration 120 : 0.42969706654548645
Loss at iteration 130 : 0.3605058193206787
Loss at iteration 140 : 0.4158819913864136
Loss at iteration 150 : 0.3676515817642212
Loss at iteration 160 : 0.4414764642715454
Loss at iteration 170 : 0.34752601385116577
Loss at iteration 180 : 0.3621019124984741
Loss at iteration 10 : 0.31708645820617676
Loss at iteration 20 : 0.3203216791152954
Loss at iteration 30 : 0.42810922861099243
Loss at iteration 40 : 0.3880820870399475
Loss at iteration 50 : 0.38907408714294434
Loss at iteration 60 : 0.3822104036808014
Loss at iteration 70 : 0.3651544749736786
Loss at iteration 80 : 0.32554662227630615
Loss at iteration 90 : 0.38167867064476013
Loss at iteration 100 : 0.40761899948120117
Loss at iteration 110 : 0.35371482372283936
Loss at iteration 120 : 0.3538764417171478
Loss at iteration 130 : 0.3035315275192261
Loss at iteration 140 : 0.38930416107177734
Loss at iteration 150 : 0.34829264879226685
Loss at iteration 160 : 0.39578694105148315
Loss at iteration 170 : 0.3895149230957031
Loss at iteration 180 : 0.4162948429584503
